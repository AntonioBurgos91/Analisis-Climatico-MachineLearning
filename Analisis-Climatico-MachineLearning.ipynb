{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8d79bd-cc1b-4675-a3b0-3dcf53b5845a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Librerías Fundamentales ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "# --- Preprocesamiento y Modelado ---\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, ConfusionMatrixDisplay,\n",
    "    r2_score, mean_squared_error, roc_auc_score, roc_curve\n",
    ")\n",
    "\n",
    "# --- Modelos Adicionales (Opcional pero recomendado) ---\n",
    "try:\n",
    "    from xgboost import XGBClassifier, XGBRegressor\n",
    "    xgb_available = True\n",
    "except ImportError:\n",
    "    xgb_available = False\n",
    "    print(\"XGBoost no está instalado. Algunas funcionalidades avanzadas de modelado no estarán disponibles.\")\n",
    "\n",
    "# --- Librerías Geográficas y Visualización Interactiva ---\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "import plotly.express as px\n",
    "\n",
    "# --- Configuraciones Adicionales ---\n",
    "%matplotlib inline \n",
    "sns.set_style(\"whitegrid\") # Estilo de gráficos más limpio\n",
    "plt.rcParams['figure.figsize'] = (10, 6) # Tamaño de figura por defecto\n",
    "warnings.filterwarnings('ignore', category=FutureWarning) # Ignorar warnings futuros de librerías\n",
    "warnings.filterwarnings('ignore', category=UserWarning) # Ignorar warnings de usuario (e.g., de Seaborn)\n",
    "\n",
    "print(\"Librerías cargadas exitosamente.\")\n",
    "if xgb_available:\n",
    "    print(\"XGBoost está disponible ✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e007e6-2b99-4a83-b68c-f91b518b41ed",
   "metadata": {},
   "source": [
    "### Celda 1: Importación de Librerías y Configuración Inicial\n",
    "\n",
    "**Propósito:** Cargar todas las herramientas necesarias para el análisis de datos, visualización y machine learning.\n",
    "\n",
    "**Detalles del Código:**\n",
    "*   **Librerías Fundamentales:** `pandas`, `numpy`, `matplotlib.pyplot`, `seaborn`, `warnings`.\n",
    "*   **Preprocesamiento y Modelado (`sklearn`):** Herramientas para división de datos, optimización, preprocesamiento (escalado, codificación, imputación), pipelines, modelos (Regresión Logística, Random Forest) y métricas.\n",
    "*   **Modelos Adicionales:** Intenta importar `XGBoost` y establece una bandera `xgb_available`.\n",
    "*   **Librerías Geográficas y Visualización Interactiva:** `geopandas`, `folium`, `plotly.express`.\n",
    "*   **Configuraciones Adicionales:** `%matplotlib inline` para mostrar gráficos en Jupyter, estilo `whitegrid` para `seaborn`, tamaño de figura por defecto, y filtros de warnings.\n",
    "\n",
    "**Resultado Esperado:**\n",
    "Mensajes indicando que las librerías se cargaron y si XGBoost está disponible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7294208-719f-4c5f-8ab1-7b20a53016a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset desde URL\n",
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/_0eYOqji3unP1tDNKWZMjg/weatherAUS-2.csv\"\n",
    "df_original = pd.read_csv(url)\n",
    "\n",
    "print(\"Dataset original cargado:\")\n",
    "df_original.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e1893f-f4ad-481d-a607-020e4b8d0b60",
   "metadata": {},
   "source": [
    "### Celda 2: Carga del Conjunto de Datos\n",
    "\n",
    "**Propósito:** Obtener los datos climáticos desde la URL proporcionada.\n",
    "\n",
    "**Detalles del Código:**\n",
    "*   Se define la `url` donde se encuentra el archivo CSV.\n",
    "*   `pd.read_csv(url)` lee el archivo CSV y lo carga en un DataFrame de pandas llamado `df_original`.\n",
    "*   `df_original.head()` muestra las primeras 5 filas del DataFrame para una inspección inicial.\n",
    "\n",
    "**Resultado Esperado:**\n",
    "Una tabla con las primeras cinco filas del conjunto de datos `weatherAUS`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0f173a-bc69-42c5-bb4f-8df3c46920eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Información general del dataset completo\n",
    "print(\"--- Información General del Dataset Completo ---\")\n",
    "df_original.info()\n",
    "print(f\"\\nDimensiones del dataset original: {df_original.shape}\")\n",
    "\n",
    "# --- Paso 1: Filtrar por ubicaciones de interés ---\n",
    "# Mantendremos el enfoque en Melbourne y sus alrededores como en el notebook original.\n",
    "locations_of_interest = ['Melbourne', 'MelbourneAirport', 'Watsonia']\n",
    "df = df_original[df_original['Location'].isin(locations_of_interest)].copy() # Usar .copy() para evitar SettingWithCopyWarning\n",
    "print(f\"\\nDataset filtrado por ubicaciones {locations_of_interest}.\")\n",
    "print(f\"Dimensiones después del filtrado por ubicación: {df.shape}\")\n",
    "\n",
    "# --- Paso 2: Inspección de valores nulos en el subconjunto filtrado ---\n",
    "print(\"\\n--- Valores Nulos ANTES de la Imputación (en el subconjunto filtrado) ---\")\n",
    "null_counts_before = df.isnull().sum()\n",
    "null_percentages_before = (df.isnull().sum() / len(df)) * 100\n",
    "missing_data_summary_before = pd.DataFrame({\n",
    "    'Null Count': null_counts_before,\n",
    "    'Percentage (%)': null_percentages_before\n",
    "})\n",
    "print(missing_data_summary_before[missing_data_summary_before['Null Count'] > 0].sort_values(by='Null Count', ascending=False))\n",
    "\n",
    "# --- Paso 3: Imputación de Valores Nulos ---\n",
    "# Identificar columnas numéricas y categóricas (excluyendo 'Date' por ahora)\n",
    "numerical_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# 'Location' ya está filtrada y no debería tener nulos ni necesitar imputación aquí.\n",
    "if 'Location' in categorical_cols:\n",
    "    categorical_cols.remove('Location')\n",
    "# 'Date' se manejará por separado y no se imputa con estas estrategias.\n",
    "if 'Date' in df.columns:\n",
    "    if 'Date' in numerical_cols: numerical_cols.remove('Date') # Aunque 'Date' no es numérico para imputar así\n",
    "    if 'Date' in categorical_cols: categorical_cols.remove('Date')\n",
    "\n",
    "\n",
    "# Imputador para columnas numéricas: media\n",
    "if numerical_cols: # Solo si hay columnas numéricas que imputar\n",
    "    num_imputer = SimpleImputer(strategy='mean')\n",
    "    df[numerical_cols] = num_imputer.fit_transform(df[numerical_cols])\n",
    "\n",
    "# Imputador para columnas categóricas: moda (valor más frecuente)\n",
    "cols_to_impute_cat = [col for col in categorical_cols if df[col].isnull().any()]\n",
    "if cols_to_impute_cat:\n",
    "    cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "    df[cols_to_impute_cat] = cat_imputer.fit_transform(df[cols_to_impute_cat])\n",
    "\n",
    "print(\"\\n--- Valores Nulos DESPUÉS de la Imputación ---\")\n",
    "null_counts_after = df.isnull().sum()\n",
    "remaining_nulls = null_counts_after[null_counts_after > 0]\n",
    "if not remaining_nulls.empty:\n",
    "    print(\"Columnas con nulos restantes:\")\n",
    "    print(remaining_nulls)\n",
    "else:\n",
    "    print(\"Todos los valores nulos (excepto potencialmente en 'Date' si tuviera) han sido imputados exitosamente.\")\n",
    "\n",
    "print(\"\\n--- Información del Dataset Después de Filtrado e Imputación ---\")\n",
    "df.info()\n",
    "print(f\"\\nDimensiones después de la limpieza: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbad5b0-c0e0-4137-8a26-d42ecf661668",
   "metadata": {},
   "source": [
    "### Celda 3: Información General, Filtrado y Manejo de Nulos Mejorado\n",
    "\n",
    "**Propósito:** Entender la estructura inicial del dataset, filtrar los datos para las ubicaciones de interés y manejar los valores faltantes de una manera más robusta que simplemente eliminando filas.\n",
    "\n",
    "**Detalles del Código:**\n",
    "1.  **Información General del Dataset Completo:** Muestra `info()` y `shape` del DataFrame original.\n",
    "2.  **Filtrado por Ubicaciones de Interés:** Crea el DataFrame `df` con datos solo de 'Melbourne', 'MelbourneAirport', 'Watsonia'.\n",
    "3.  **Inspección de Valores Nulos (Subconjunto Filtrado):** Muestra cuentas y porcentajes de nulos *antes* de la imputación.\n",
    "4.  **Imputación de Valores Nulos:**\n",
    "    *   Las columnas numéricas se imputan con la media (`SimpleImputer(strategy='mean')`).\n",
    "    *   Las columnas categóricas (excepto 'Location' y 'Date') se imputan con la moda (`SimpleImputer(strategy='most_frequent')`).\n",
    "5.  **Verificación Post-Imputación:** Se muestra `info()`, `shape`, y las primeras filas del DataFrame `df` limpio y filtrado.\n",
    "\n",
    "**Resultado Esperado:**\n",
    "*   Información sobre el dataset original.\n",
    "*   Dimensiones antes y después del filtrado por ubicación.\n",
    "*   Un resumen de los valores nulos antes y después de la imputación.\n",
    "*   Información del DataFrame `df` después de la imputación, idealmente sin valores nulos (excepto 'Date' si tuviera originalmente, lo cual es improbable para esta columna).\n",
    "*   Las primeras filas del DataFrame `df` limpio y filtrado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe05de35-bfd5-4ec0-9f8f-c22144e0edeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Ingeniería de Características a partir de la Columna 'Date' ---\n",
    "\n",
    "# Convertir la columna 'Date' a formato datetime\n",
    "# Es posible que 'Date' tenga nulos si el CSV original los tuviera y no se filtraran por ubicación.\n",
    "# Si 'Date' tiene nulos, pd.to_datetime los convertirá a NaT (Not a Time).\n",
    "# Estos NaT se propagarán a las columnas derivadas (Year, Month, etc.) como NaN (para flotantes) o NaT.\n",
    "# Si hay NaTs, se pueden eliminar esas filas o imputar la fecha si es crucial.\n",
    "# Dado que el dropna() original era agresivo, es posible que no queden NaTs en 'Date'\n",
    "# después de la imputación general (aunque 'Date' fue excluida de la imputación explícita).\n",
    "# Verificamos y manejamos si es necesario.\n",
    "if df['Date'].isnull().any():\n",
    "    print(f\"Valores nulos encontrados en 'Date': {df['Date'].isnull().sum()}. Eliminando estas filas.\")\n",
    "    df.dropna(subset=['Date'], inplace=True)\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Extraer componentes de la fecha\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['Day'] = df['Date'].dt.day\n",
    "df['DayOfYear'] = df['Date'].dt.dayofyear # Nueva característica: día del año\n",
    "\n",
    "# Definir función para determinar la estación del año (Hemisferio Sur)\n",
    "def date_to_season(date_obj):\n",
    "    month = date_obj.month\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'Verano'  # Summer\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'Otoño'   # Autumn\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'Invierno'# Winter\n",
    "    else: # 9, 10, 11\n",
    "        return 'Primavera' # Spring\n",
    "\n",
    "# Aplicar la función para crear la columna 'Season'\n",
    "df['Season'] = df['Date'].apply(date_to_season)\n",
    "\n",
    "print(\"\\nNuevas características de fecha y estación añadidas:\")\n",
    "df[['Date', 'Year', 'Month', 'Day', 'DayOfYear', 'Season']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281ed063-48ce-4071-934f-a7618481f020",
   "metadata": {},
   "source": [
    "### Celda 4: Ingeniería de Características (Fecha y Estación)\n",
    "\n",
    "**Propósito:** Transformar la columna 'Date' y extraer información útil como el año, mes, día y la estación del año, lo cual puede ser relevante para el análisis climático.\n",
    "\n",
    "**Detalles del Código:**\n",
    "1.  **Manejo de Nulos en 'Date':** Se verifica si hay valores nulos en la columna 'Date' (que se convertirían en `NaT` por `pd.to_datetime`). Si existen, esas filas se eliminan.\n",
    "2.  **Conversión de 'Date':** `df['Date']` se convierte a tipo `datetime`.\n",
    "3.  **Extracción de Componentes de Fecha:** Se crean nuevas columnas: 'Year', 'Month', 'Day', y 'DayOfYear'.\n",
    "4.  **Determinación de la Estación:** Se define y aplica la función `date_to_season` para crear la columna 'Season' (Verano, Otoño, Invierno, Primavera) para el Hemisferio Sur.\n",
    "\n",
    "**Resultado Esperado:**\n",
    "*   Un mensaje si se eliminaron filas debido a nulos en 'Date'.\n",
    "*   Un mensaje indicando que las nuevas características han sido añadidas.\n",
    "*   Una tabla mostrando las primeras cinco filas de las columnas 'Date', 'Year', 'Month', 'Day', 'DayOfYear', y 'Season'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00be4a87-5148-401f-bbf0-8fe8a997f768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualización: Temperatura Máxima Promedio por Mes y Ubicación ---\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.lineplot(data=df, x='Month', y='MaxTemp', hue='Location', estimator='mean', errorbar='sd', lw=2)\n",
    "plt.title('Temperatura Máxima Promedio Mensual por Ubicación (+/- Desv. Est.)', fontsize=16)\n",
    "plt.xlabel('Mes del Año', fontsize=12)\n",
    "plt.ylabel('Temperatura Máxima Promedio (°C)', fontsize=12)\n",
    "plt.xticks(ticks=range(1, 13), labels=['Ene', 'Feb', 'Mar', 'Abr', 'May', 'Jun', 'Jul', 'Ago', 'Sep', 'Oct', 'Nov', 'Dic'])\n",
    "plt.legend(title='Ubicación')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365db5fe-e1ff-44e4-8a28-615afabd20d5",
   "metadata": {},
   "source": [
    "### Celda 5: EDA - Temperatura Máxima Promedio por Mes y Ubicación\n",
    "\n",
    "**Propósito:** Explorar cómo varía la temperatura máxima promedio a lo largo de los meses para las diferentes ubicaciones seleccionadas.\n",
    "\n",
    "**Detalles del Código:**\n",
    "*   `sns.lineplot` crea un gráfico de líneas mostrando la `MaxTemp` promedio (`estimator='mean'`) por `Month` para cada `Location`.\n",
    "*   `errorbar='sd'` muestra la desviación estándar como una banda de error.\n",
    "*   Se personalizan etiquetas, título, y las marcas del eje X para mostrar nombres de meses.\n",
    "\n",
    "**Resultado Esperado:**\n",
    "Un gráfico de líneas con tres curvas (una para cada ubicación), representando la tendencia de la temperatura máxima promedio mensual, con bandas de error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b47a2e8-c394-436b-ab11-0196c0804fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- EDA: Distribución de la Variable Objetivo 'RainTomorrow' ---\n",
    "# Es importante entender el balance de clases antes de la modelización\n",
    "\n",
    "# Asegurarse de que 'RainTomorrow' existe y no tiene solo NaNs (ya imputamos)\n",
    "if 'RainTomorrow' in df.columns:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    \n",
    "    # Determinar el tipo de 'RainTomorrow' para el conteo y porcentajes\n",
    "    if df['RainTomorrow'].dtype == 'object': # Asume 'Yes'/'No'\n",
    "        sns.countplot(data=df, x='RainTomorrow', palette='viridis')\n",
    "        counts = df['RainTomorrow'].value_counts()\n",
    "        percentages = df['RainTomorrow'].value_counts(normalize=True) * 100\n",
    "        class_labels = counts.index.tolist() # ['No', 'Yes'] o viceversa\n",
    "    elif pd.api.types.is_numeric_dtype(df['RainTomorrow']): # Asume 0/1\n",
    "        # Mapear temporalmente para etiquetas en el gráfico si es numérico\n",
    "        temp_rain_tomorrow_labels = df['RainTomorrow'].map({0:'No', 1:'Yes'})\n",
    "        sns.countplot(x=temp_rain_tomorrow_labels, order=['No','Yes'], palette='viridis')\n",
    "        counts = temp_rain_tomorrow_labels.value_counts()\n",
    "        percentages = temp_rain_tomorrow_labels.value_counts(normalize=True) * 100\n",
    "        class_labels = counts.index.tolist()\n",
    "    else:\n",
    "        print(\"Tipo de 'RainTomorrow' no reconocido para countplot.\")\n",
    "        counts, percentages, class_labels = None, None, None\n",
    "\n",
    "    if counts is not None:\n",
    "        plt.title('Distribución de la Variable Objetivo: RainTomorrow', fontsize=15)\n",
    "        plt.xlabel('¿Lloverá Mañana?', fontsize=12)\n",
    "        plt.ylabel('Frecuencia', fontsize=12)\n",
    "\n",
    "        # Ajustar el bucle de anotaciones para que coincida con el orden del countplot\n",
    "        # El orden de sns.countplot puede no ser el mismo que el de value_counts().index\n",
    "        # Por ello, iteramos sobre los patches (barras) del gráfico\n",
    "        ax = plt.gca()\n",
    "        for i, p in enumerate(ax.patches):\n",
    "            # El label de la barra actual (ej. 'No' o 'Yes')\n",
    "            current_label = class_labels[i] if ax.get_xticklabels()[i].get_text() in class_labels else ax.get_xticklabels()[i].get_text()\n",
    "\n",
    "            # Asegurar que el current_label exista en counts y percentages\n",
    "            if current_label in counts.index:\n",
    "                count_val = counts[current_label]\n",
    "                percentage_val = percentages[current_label]\n",
    "                ax.text(p.get_x() + p.get_width()/2., p.get_height() + 30, f'{count_val}\\n({percentage_val:.1f}%)',\n",
    "                        ha='center', va='bottom', fontsize=10, color='black')\n",
    "            else: # Fallback si el label no coincide, menos probable con el ajuste\n",
    "                ax.text(p.get_x() + p.get_width()/2., p.get_height() + 30, f'{p.get_height():.0f}',\n",
    "                        ha='center', va='bottom', fontsize=10, color='black')\n",
    "        plt.show()\n",
    "\n",
    "        if percentages.min() < 30: # Umbral arbitrario para desbalance\n",
    "            print(f\"Advertencia: La variable 'RainTomorrow' parece desbalanceada: \\n{percentages}\")\n",
    "            imbalanced_target = True\n",
    "        else:\n",
    "            imbalanced_target = False\n",
    "    else:\n",
    "        imbalanced_target = False # Default\n",
    "else:\n",
    "    print(\"La columna 'RainTomorrow' no se encuentra en el DataFrame.\")\n",
    "    imbalanced_target = False # Asumir que no es un problema si no existe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d866b122-3c11-4295-9ad1-352cd0d7b07b",
   "metadata": {},
   "source": [
    "### Celda 6: EDA - Distribución de la Variable Objetivo ('RainTomorrow')\n",
    "\n",
    "**Propósito:** Analizar la distribución de la variable objetivo `RainTomorrow` para identificar desbalance de clases.\n",
    "\n",
    "**Detalles del Código:**\n",
    "*   Se utiliza `sns.countplot` para visualizar la frecuencia de 'Yes' y 'No' (o 0 y 1).\n",
    "*   El código se adapta si `RainTomorrow` es de tipo `object` o numérico.\n",
    "*   Se calculan y muestran porcentajes en las barras del gráfico.\n",
    "*   Se establece una bandera `imbalanced_target` si una clase representa menos del 30% del total, lo cual es útil para estrategias de modelado posteriores.\n",
    "\n",
    "**Resultado Esperado:**\n",
    "Un gráfico de barras mostrando la frecuencia y porcentaje de cada clase de `RainTomorrow`. Un mensaje de advertencia si se detecta desbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e39090-3aec-44b6-ba80-c4521b0662b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- EDA: Matriz de Correlación de Características Numéricas ---\n",
    "# Usamos df que ya tiene las características de fecha procesadas.\n",
    "numerical_features_for_corr = df.select_dtypes(include=np.number).columns.tolist()\n",
    "# Excluir coordenadas si no se quieren en la correlación principal, o día/mes/año si se prefiere season\n",
    "cols_to_exclude_from_corr = ['Year', 'Month', 'Day'] # Lat/Lon no están en 'df' aún.\n",
    "numerical_features_for_corr = [col for col in numerical_features_for_corr if col not in cols_to_exclude_from_corr]\n",
    "\n",
    "if numerical_features_for_corr:\n",
    "    correlation_matrix = df[numerical_features_for_corr].corr()\n",
    "\n",
    "    plt.figure(figsize=(18, 14)) # Aumentado tamaño para más variables\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5, annot_kws={\"size\": 8})\n",
    "    plt.title('Matriz de Correlación de Características Numéricas', fontsize=18)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout() # Ajusta el layout para que no se corten las etiquetas\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No hay características numéricas para generar la matriz de correlación.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de35b5c-5f89-475e-9ea8-08d7dc8f76ea",
   "metadata": {},
   "source": [
    "### Celda 7: EDA - Matriz de Correlación\n",
    "\n",
    "**Propósito:** Visualizar las correlaciones lineales entre las características numéricas.\n",
    "\n",
    "**Detalles del Código:**\n",
    "*   Se seleccionan las columnas numéricas del DataFrame `df`.\n",
    "*   Se excluyen 'Year', 'Month', 'Day' de la matriz principal de correlación.\n",
    "*   Se calcula la matriz de correlación (`.corr()`).\n",
    "*   Se visualiza usando `sns.heatmap` con anotaciones y una paleta de colores `coolwarm`.\n",
    "\n",
    "**Resultado Esperado:**\n",
    "Un mapa de calor mostrando los coeficientes de correlación entre pares de variables numéricas. Ayuda a identificar multicolinealidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb0a825-a2e1-4233-8ed3-1cb6eda3a368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualización: Distribución de Temperatura Máxima por Estación y Ubicación ---\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.boxplot(data=df, x='Season', y='MaxTemp', hue='Location', palette='viridis',\n",
    "            order=['Verano', 'Otoño', 'Invierno', 'Primavera']) # Asegurar orden de estaciones\n",
    "plt.title('Distribución de Temperatura Máxima por Estación y Ubicación', fontsize=16)\n",
    "plt.xlabel('Estación del Año', fontsize=12)\n",
    "plt.ylabel('Temperatura Máxima (°C)', fontsize=12)\n",
    "plt.legend(title='Ubicación', loc='upper right')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b42daf-d89f-4f7f-a937-3c82376ad188",
   "metadata": {},
   "source": [
    "### Celda 8: EDA - Distribución de Temperatura Máxima por Estación y Ubicación\n",
    "\n",
    "**Propósito:** Analizar cómo se distribuye `MaxTemp` para cada estación y ubicación usando diagramas de caja.\n",
    "\n",
    "**Detalles del Código:**\n",
    "*   `sns.boxplot` crea los diagramas de caja.\n",
    "*   `x='Season'`, `y='MaxTemp'`, `hue='Location'`.\n",
    "*   `order` se usa para asegurar el orden cronológico de las estaciones en el eje X.\n",
    "\n",
    "**Resultado Esperado:**\n",
    "Un conjunto de diagramas de caja mostrando la distribución de `MaxTemp` (mediana, cuartiles, outliers) para cada combinación de estación y ubicación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5a9a0a-0086-455e-9a72-b63cf1b21146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualización: Lluvia Acumulada Mensual por Ubicación ---\n",
    "# Agrupar por ubicación y mes, y sumar la lluvia\n",
    "rain_summary_monthly = df.groupby(['Location', 'Month'])['Rainfall'].sum().reset_index()\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.lineplot(data=rain_summary_monthly, x='Month', y='Rainfall', hue='Location', marker='o', lw=2)\n",
    "plt.title('Lluvia Total Acumulada Mensual por Ubicación', fontsize=16)\n",
    "plt.xlabel('Mes del Año', fontsize=12)\n",
    "plt.ylabel('Lluvia Total Acumulada (mm)', fontsize=12)\n",
    "plt.xticks(ticks=range(1, 13), labels=['Ene', 'Feb', 'Mar', 'Abr', 'May', 'Jun', 'Jul', 'Ago', 'Sep', 'Oct', 'Nov', 'Dic'])\n",
    "plt.legend(title='Ubicación')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a3321f-c72c-44c5-a7ec-42f3ea082ef4",
   "metadata": {},
   "source": [
    "### Celda 9: EDA - Lluvia Acumulada Mensual por Ubicación\n",
    "\n",
    "**Propósito:** Analizar y comparar la cantidad total de lluvia acumulada cada mes para las diferentes ubicaciones.\n",
    "\n",
    "**Detalles del Código:**\n",
    "*   Los datos se agrupan por `Location` y `Month`, y se suma `Rainfall`.\n",
    "*   `sns.lineplot` visualiza esta lluvia acumulada mensual.\n",
    "\n",
    "**Resultado Esperado:**\n",
    "Un gráfico de líneas mostrando la tendencia de la lluvia total acumulada a lo largo de los meses para cada ubicación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db39c3fb-e1d5-4656-8106-a94bc29d63b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualización: Heatmap de Temperatura Máxima Promedio por Mes y Ciudad ---\n",
    "# Crear tabla pivote: Meses como índice, Ubicaciones como columnas, Temperatura Máxima promedio como valores\n",
    "pivot_temp_avg = df.pivot_table(index='Month', columns='Location', values='MaxTemp', aggfunc='mean')\n",
    "\n",
    "# Ordenar el índice (meses) para que aparezcan en orden cronológico\n",
    "pivot_temp_avg = pivot_temp_avg.sort_index()\n",
    "# Mapear números de mes a nombres para mejor visualización en el eje Y\n",
    "month_names = ['Ene', 'Feb', 'Mar', 'Abr', 'May', 'Jun', 'Jul', 'Ago', 'Sep', 'Oct', 'Nov', 'Dic']\n",
    "pivot_temp_avg.index = [month_names[i-1] for i in pivot_temp_avg.index]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(pivot_temp_avg, annot=True, cmap='YlOrRd', fmt=\".1f\", linewidths=.5, cbar_kws={'label': 'Temperatura Máxima Promedio (°C)'})\n",
    "plt.title(\"Temperatura Máxima Promedio (°C) por Mes y Ubicación\", fontsize=16)\n",
    "plt.xlabel(\"Ubicación\", fontsize=12)\n",
    "plt.ylabel(\"Mes del Año\", fontsize=12)\n",
    "plt.yticks(rotation=0) # Asegurar que las etiquetas de los meses sean horizontales\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d831c40-dce7-4246-a9b5-464ed60668a8",
   "metadata": {},
   "source": [
    "### Celda 10: EDA - Heatmap de Temperatura Máxima Promedio por Mes y Ubicación\n",
    "\n",
    "**Propósito:** Presentar de forma concisa la temperatura máxima promedio para cada combinación de mes y ubicación.\n",
    "\n",
    "**Detalles del Código:**\n",
    "*   `df.pivot_table` crea una tabla con meses como filas, ubicaciones como columnas, y `MaxTemp` promedio como valores.\n",
    "*   Los meses se ordenan y se etiquetan con nombres.\n",
    "*   `sns.heatmap` visualiza esta tabla pivote.\n",
    "\n",
    "**Resultado Esperado:**\n",
    "Un mapa de calor donde cada celda coloreada representa la `MaxTemp` promedio para un mes y ubicación específicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60dc82f-50d5-4384-bc05-5f4f785e9fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualización: Humedad Promedio a las 3PM por Estación y Ubicación ---\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "#Convertir 'Season' a un tipo de datos categórico con orden específico\n",
    "season_order = ['Verano', 'Otoño', 'Invierno', 'Primavera']\n",
    "df['Season'] = pd.Categorical(df['Season'], categories=season_order, ordered=True)\n",
    "\n",
    "# Ahora el lineplot respetará el orden de las categorías\n",
    "sns.lineplot(data=df, x='Season', y='Humidity3pm', hue='Location', estimator='mean', \n",
    "             errorbar='sd', marker='o', lw=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fdda79-9788-4965-bab0-697f0a6ab68c",
   "metadata": {},
   "source": [
    "### Celda 11: EDA - Humedad Promedio a las 3PM por Estación del Año y Ubicación\n",
    "\n",
    "**Propósito:** Analizar cómo varía la `Humidity3pm` promedio a lo largo de las estaciones para cada ubicación.\n",
    "\n",
    "**Detalles del Código:**\n",
    "*   `sns.lineplot` muestra la `Humidity3pm` promedio por `Season` y `Location`.\n",
    "*   `order` se usa para el eje X de estaciones.\n",
    "\n",
    "**Resultado Esperado:**\n",
    "Un gráfico de líneas mostrando la humedad promedio a las 3 PM a través de las cuatro estaciones para cada ubicación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85693d1-92dc-41a8-897c-1f28140b94b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Preparación de Datos Geográficos ---\n",
    "\n",
    "# Coordenadas aproximadas para las ubicaciones de interés\n",
    "coords = {\n",
    "    'Melbourne': (-37.8136, 144.9631),\n",
    "    'MelbourneAirport': (-37.6733, 144.8433),\n",
    "    'Watsonia': (-37.7167, 145.0833),\n",
    "}\n",
    "\n",
    "# Crear un DataFrame con las coordenadas\n",
    "coord_df = pd.DataFrame.from_dict(coords, orient='index', columns=['Lat', 'Lon']).reset_index()\n",
    "coord_df = coord_df.rename(columns={'index': 'Location'}) # Evitar inplace=True\n",
    "\n",
    "# Fusionar las coordenadas con el DataFrame principal 'df'\n",
    "df_geo = pd.merge(df, coord_df, on='Location', how='left')\n",
    "\n",
    "# Crear un GeoDataFrame a partir del DataFrame fusionado\n",
    "try:\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        df_geo,\n",
    "        geometry=gpd.points_from_xy(df_geo['Lon'], df_geo['Lat']),\n",
    "        crs=\"EPSG:4326\" # WGS 84\n",
    "    )\n",
    "    print(\"GeoDataFrame creado exitosamente.\")\n",
    "    gdf.head()\n",
    "except Exception as e:\n",
    "    print(f\"Error al crear GeoDataFrame: {e}\")\n",
    "    gdf = None # Establecer gdf a None si falla la creación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d240597f-680d-4915-8b27-b9c393873271",
   "metadata": {},
   "source": [
    "### Celda 12: Preparación de Datos Geográficos\n",
    "\n",
    "**Propósito:** Enriquecer el conjunto de datos con coordenadas geoespaciales y convertirlo en un `GeoDataFrame`.\n",
    "\n",
    "**Detalles del Código:**\n",
    "1.  Se define un diccionario `coords` con latitud y longitud para las ubicaciones.\n",
    "2.  Se crea `coord_df` a partir de este diccionario.\n",
    "3.  `df_geo` se crea fusionando `df` con `coord_df` por 'Location'.\n",
    "4.  `gdf` (GeoDataFrame) se crea a partir de `df_geo`, especificando la geometría a partir de 'Lon' y 'Lat', y el CRS (Sistema de Referencia de Coordenadas) como EPSG:4326.\n",
    "\n",
    "**Resultado Esperado:**\n",
    "Un mensaje de éxito y las primeras filas del `GeoDataFrame` `gdf`, que ahora incluye una columna 'geometry'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4f0e6c-f6b9-41e2-acf0-d1d9dfab15ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualización Geográfica: Mapa Interactivo con Marcadores ---\n",
    "\n",
    "if gdf is not None:\n",
    "    # Calcular la temperatura máxima promedio y el total de lluvia por ubicación\n",
    "    # Para DaysWithRain, necesitamos asegurar que RainToday sea del tipo correcto para la lambda\n",
    "    # Si RainToday ya fue mapeada a 0/1 en `df` (y por ende en `gdf`), la lambda debe cambiar.\n",
    "    # Revisando el flujo, RainToday en `df` (y `gdf`) aún es Yes/No.\n",
    "    \n",
    "    location_summary = gdf.groupby('Location').agg(\n",
    "        Lat=('Lat', 'first'),\n",
    "        Lon=('Lon', 'first'),\n",
    "        AvgMaxTemp=('MaxTemp', 'mean'),\n",
    "        TotalRainfall=('Rainfall', 'sum'),\n",
    "        DaysWithRain=('RainToday', lambda x: (x == 'Yes').sum()) \n",
    "    ).reset_index()\n",
    "\n",
    "    # Crear un mapa base centrado aproximadamente en Melbourne\n",
    "    map_center = [location_summary['Lat'].mean(), location_summary['Lon'].mean()]\n",
    "    m = folium.Map(location=map_center, zoom_start=10, tiles=\"CartoDB positron\")\n",
    "\n",
    "    # Añadir marcadores para cada ubicación\n",
    "    for _, row in location_summary.iterrows():\n",
    "        popup_html = f\"\"\"\n",
    "        <b>Ubicación:</b> {row['Location']}<br>\n",
    "        <b>Temp. Máx Promedio:</b> {row['AvgMaxTemp']:.1f}°C<br>\n",
    "        <b>Lluvia Total Acumulada:</b> {row['TotalRainfall']:.1f} mm<br>\n",
    "        <b>Días con Lluvia:</b> {row['DaysWithRain']}\n",
    "        \"\"\"\n",
    "        iframe = folium.IFrame(html=popup_html, width=250, height=100)\n",
    "        popup = folium.Popup(iframe, max_width=250)\n",
    "        \n",
    "        folium.Marker(\n",
    "            location=[row['Lat'], row['Lon']],\n",
    "            popup=popup,\n",
    "            tooltip=f\"{row['Location']}: {row['AvgMaxTemp']:.1f}°C\",\n",
    "            icon=folium.Icon(color=\"blue\", icon=\"cloud\", prefix='fa')\n",
    "        ).add_to(m)\n",
    "\n",
    "    print(\"Mapa con marcadores generado. Se mostrará a continuación:\")\n",
    "    display(m)\n",
    "else:\n",
    "    print(\"GeoDataFrame no está disponible, no se puede generar el mapa.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54baf664-18f2-4485-bc19-7145c074ceef",
   "metadata": {},
   "source": [
    "### Celda 13: Mapa Interactivo con Folium (Marcadores)\n",
    "\n",
    "**Propósito:** Visualizar las ubicaciones en un mapa interactivo con información climática resumida.\n",
    "\n",
    "**Detalles del Código:**\n",
    "*   Se agrupan datos del `gdf` por `Location` para calcular `AvgMaxTemp`, `TotalRainfall`, y `DaysWithRain`.\n",
    "*   Se crea un mapa `folium.Map` centrado en la región.\n",
    "*   Se itera sobre `location_summary` para añadir un `folium.Marker` para cada ubicación, con un `popup` HTML formateado y un `tooltip`.\n",
    "\n",
    "**Resultado Esperado:**\n",
    "Un mapa interactivo de Folium con marcadores para cada ubicación. Los popups mostrarán estadísticas climáticas al hacer clic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4fa4db-4a9b-4780-a4bb-c3c4138ecbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualización Interactiva: Relación MinTemp y MaxTemp por Mes (Animada) ---\n",
    "if gdf is not None:\n",
    "    # Subconjunto para animación (evitar demasiados frames y datos)\n",
    "    # Filtrar por años más recientes para una animación más manejable\n",
    "    df_anim = gdf[gdf['Year'] >= gdf['Year'].max() - 2].copy() # Últimos 3 años aprox.\n",
    "    \n",
    "    if not df_anim.empty:\n",
    "        df_anim['DateStr'] = df_anim['Date'].dt.strftime('%Y-%m-%d') # Para animation_group\n",
    "\n",
    "        fig_anim = px.scatter(\n",
    "            df_anim,\n",
    "            x=\"MinTemp\",\n",
    "            y=\"MaxTemp\",\n",
    "            color=\"Location\",\n",
    "            animation_frame=\"Month\", # Animar por mes\n",
    "            animation_group=\"DateStr\", # Agrupar por fecha para transiciones suaves\n",
    "            size=\"Rainfall\",       # El tamaño del punto representa la cantidad de lluvia\n",
    "            hover_name=\"Location\", # Información al pasar el cursor\n",
    "            title=\"Relación MinTemp vs MaxTemp (Animado por Mes, Tamaño por Lluvia)\",\n",
    "            labels={\"MinTemp\": \"Temperatura Mínima (°C)\", \"MaxTemp\": \"Temperatura Máxima (°C)\", \"Rainfall\": \"Lluvia (mm)\"},\n",
    "            size_max=30,           # Tamaño máximo de las burbujas\n",
    "            height=700,\n",
    "            # Para asegurar que la animación se repita y los ejes se mantengan consistentes:\n",
    "            range_x=[df_anim['MinTemp'].min()-2, df_anim['MinTemp'].max()+2],\n",
    "            range_y=[df_anim['MaxTemp'].min()-2, df_anim['MaxTemp'].max()+2]\n",
    "        )\n",
    "\n",
    "        # Mejorar el layout de la animación\n",
    "        fig_anim.update_layout(\n",
    "            transition={'duration': 500}, # Duración de la transición entre frames\n",
    "            xaxis_title=\"Temperatura Mínima (°C)\",\n",
    "            yaxis_title=\"Temperatura Máxima (°C)\",\n",
    "            legend_title_text='Ubicación'\n",
    "        )\n",
    "        # Ajustar la velocidad de la animación (más bajo es más rápido)\n",
    "        if fig_anim.layout.updatemenus: # Comprobar si existen updatemenus\n",
    "            fig_anim.layout.updatemenus[0].buttons[0].args[1]['frame']['duration'] = 1000 # Duración por frame en ms\n",
    "            fig_anim.layout.updatemenus[0].buttons[0].args[1]['transition']['duration'] = 300 # Duración de transición\n",
    "\n",
    "        print(\"Generando gráfico animado. Esto puede tardar unos momentos...\")\n",
    "        fig_anim.show()\n",
    "    else:\n",
    "        print(\"No hay datos suficientes para la animación después del filtrado por año.\")\n",
    "else:\n",
    "    print(\"GeoDataFrame no está disponible para esta visualización.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212cb058-9aa8-4394-b2b4-d0aaf0740833",
   "metadata": {},
   "source": [
    "### Celda 14: Animación Interactiva con Plotly Express\n",
    "\n",
    "**Propósito:** Crear una visualización animada de `MinTemp` vs `MaxTemp`, con el tamaño de los puntos representando `Rainfall`, animada por `Month`.\n",
    "\n",
    "**Detalles del Código:**\n",
    "*   Se crea un subconjunto `df_anim` con los datos de los últimos 3 años para la animación.\n",
    "*   `px.scatter` genera el gráfico animado.\n",
    "    *   `animation_frame=\"Month\"` y `animation_group=\"DateStr\"`.\n",
    "    *   `size=\"Rainfall\"` y `color=\"Location\"`.\n",
    "*   Se ajustan los rangos de los ejes y la velocidad/transición de la animación.\n",
    "\n",
    "**Resultado Esperado:**\n",
    "Un gráfico de dispersión animado e interactivo de Plotly, que permite explorar la relación entre MinTemp, MaxTemp y Rainfall a lo largo de los meses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a698d1e-aa6d-42ba-a959-45817a0b1dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Preparación de Datos para Modelado de Clasificación (Predecir 'RainTomorrow') ---\n",
    "if gdf is not None:\n",
    "    df_ml = gdf.copy() # Usar el GeoDataFrame que tiene toda la información\n",
    "\n",
    "    # --- 1. Selección de Características (Features) y Variable Objetivo (Target) ---\n",
    "    features_cls = ['MinTemp', 'MaxTemp', 'Rainfall', 'Humidity9am', 'Humidity3pm',\n",
    "                    'WindGustSpeed', 'Pressure9am', 'Pressure3pm', 'Temp9am', 'Temp3pm',\n",
    "                    'WindSpeed9am', 'WindSpeed3pm', 'DayOfYear', \n",
    "                    'RainToday', 'Season', 'WindGustDir', 'WindDir9am', 'WindDir3pm']\n",
    "    target_cls = 'RainTomorrow'\n",
    "\n",
    "    # Asegurarse de que todas las features y el target existen\n",
    "    existing_features_cls = [col for col in features_cls if col in df_ml.columns]\n",
    "    if len(existing_features_cls) != len(features_cls):\n",
    "        missing_in_features_cls = list(set(features_cls) - set(existing_features_cls))\n",
    "        print(f\"Advertencia: Las siguientes características no se encuentran en df_ml y serán excluidas: {missing_in_features_cls}\")\n",
    "        features_cls = existing_features_cls\n",
    "        \n",
    "    if target_cls not in df_ml.columns:\n",
    "        print(f\"ERROR CRÍTICO: La variable objetivo '{target_cls}' no existe. No se puede continuar con la clasificación.\")\n",
    "        X_cls, y_cls = None, None \n",
    "    elif not features_cls:\n",
    "        print(f\"ERROR CRÍTICO: No hay características válidas para la clasificación.\")\n",
    "        X_cls, y_cls = None, None\n",
    "    else:\n",
    "        X_cls = df_ml[features_cls]\n",
    "        y_cls = df_ml[target_cls]\n",
    "\n",
    "    if X_cls is not None and y_cls is not None:\n",
    "        # --- 2. Codificación de Variables Categóricas y Binarias ---\n",
    "        y_cls = y_cls.map({'No': 0, 'Yes': 1}).astype(int)\n",
    "        \n",
    "        if 'RainToday' in X_cls.columns and X_cls['RainToday'].dtype == 'object':\n",
    "             X_cls.loc[:, 'RainToday'] = X_cls['RainToday'].map({'No': 0, 'Yes': 1}).astype(int)\n",
    "\n",
    "        # --- 3. Identificar Columnas Numéricas y Categóricas para el Preprocesador ---\n",
    "        numerical_cols_cls = X_cls.select_dtypes(include=np.number).columns.tolist()\n",
    "        categorical_cols_cls = X_cls.select_dtypes(include='object').columns.tolist()\n",
    "        \n",
    "        print(f\"Características numéricas para clasificación: {numerical_cols_cls}\")\n",
    "        print(f\"Características categóricas para clasificación: {categorical_cols_cls}\")\n",
    "\n",
    "        # --- 4. Definir el Preprocesador con ColumnTransformer ---\n",
    "        numeric_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler())])\n",
    "\n",
    "        categorical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))])\n",
    "\n",
    "        preprocessor_cls = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', numeric_transformer, numerical_cols_cls),\n",
    "                ('cat', categorical_transformer, categorical_cols_cls)], \n",
    "            remainder='passthrough')\n",
    "        \n",
    "        # --- 5. División de Datos en Entrenamiento y Prueba ---\n",
    "        X_train_cls, X_test_cls, y_train_cls, y_test_cls = train_test_split(\n",
    "            X_cls, y_cls,\n",
    "            test_size=0.25,\n",
    "            random_state=42,\n",
    "            stratify=y_cls)\n",
    "\n",
    "        print(f\"Dimensiones de X_train_cls: {X_train_cls.shape}, y_train_cls: {y_train_cls.shape}\")\n",
    "        print(f\"Dimensiones de X_test_cls: {X_test_cls.shape}, y_test_cls: {y_test_cls.shape}\")\n",
    "        print(f\"Distribución de 'RainTomorrow' en y_train_cls:\\n{y_train_cls.value_counts(normalize=True)}\")\n",
    "    else:\n",
    "        # Asegurar que las variables se definan como None si falla la preparación\n",
    "        X_train_cls, X_test_cls, y_train_cls, y_test_cls, preprocessor_cls = [None]*5\n",
    "        print(\"No se pudo preparar X_cls o y_cls. Revise los mensajes de error.\")\n",
    "else:\n",
    "    print(\"GeoDataFrame no está disponible, no se puede preparar datos para ML.\")\n",
    "    X_cls, y_cls, X_train_cls, X_test_cls, y_train_cls, y_test_cls, preprocessor_cls = [None]*7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1109c4-fb75-40ec-bbac-d0c38b41fdb8",
   "metadata": {},
   "source": [
    "### Celda 15: Preparación de Datos para Modelado de Clasificación (`RainTomorrow`)\n",
    "\n",
    "**Propósito:** Preparar los datos para entrenar modelos que predigan `RainTomorrow`.\n",
    "\n",
    "**Detalles del Código:**\n",
    "1.  `df_ml` se crea como copia de `gdf`.\n",
    "2.  Se definen `features_cls` y `target_cls`. Se verifica su existencia.\n",
    "3.  `RainTomorrow` (objetivo) y `RainToday` (característica) se mapean de 'Yes'/'No' a 1/0. Se usa `.loc` para la asignación en `X_cls` para evitar `SettingWithCopyWarning`.\n",
    "4.  Se identifican columnas numéricas y categóricas para el `ColumnTransformer`.\n",
    "5.  Se define `preprocessor_cls` con transformadores para escalar datos numéricos y aplicar One-Hot Encoding a categóricos, incluyendo imputación como salvaguarda.\n",
    "6.  Los datos se dividen en conjuntos de entrenamiento y prueba (`train_test_split`) con `stratify=y_cls` para manejar el desbalance de clases.\n",
    "\n",
    "**Resultado Esperado:**\n",
    "Mensajes sobre las características, las dimensiones de los conjuntos de datos de entrenamiento/prueba, y la distribución de `RainTomorrow` en el conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11285a1f-120a-4a8f-baf7-84fa42165513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Modelado de Clasificación: RandomForest y LogisticRegression con Optimización ---\n",
    "\n",
    "# Verificar que los datos de entrenamiento estén disponibles y el preprocesador exista\n",
    "if 'X_train_cls' in globals() and X_train_cls is not None and \\\n",
    "   'y_train_cls' in globals() and y_train_cls is not None and \\\n",
    "   'preprocessor_cls' in globals() and preprocessor_cls is not None:\n",
    "\n",
    "    # --- Modelo 1: Logistic Regression ---\n",
    "    print(\"--- Entrenando Regresión Logística ---\")\n",
    "    # Determinar class_weight basado en imbalanced_target (definido en Celda 6)\n",
    "    lr_class_weight = None\n",
    "    if 'imbalanced_target' in globals() and imbalanced_target:\n",
    "        lr_class_weight = 'balanced'\n",
    "\n",
    "    pipeline_lr = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor_cls),\n",
    "        ('classifier', LogisticRegression(solver='liblinear', random_state=42,\n",
    "                                          class_weight=lr_class_weight))\n",
    "    ])\n",
    "\n",
    "    param_grid_lr = {\n",
    "        'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
    "        'classifier__penalty': ['l1', 'l2']\n",
    "    }\n",
    "    # StratifiedKFold es bueno para clasificación, especialmente con desbalance\n",
    "    cv_stratified = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    grid_search_lr = GridSearchCV(pipeline_lr, param_grid_lr, cv=cv_stratified, scoring='roc_auc', n_jobs=-1, verbose=0)\n",
    "    grid_search_lr.fit(X_train_cls, y_train_cls)\n",
    "\n",
    "    print(f\"Mejores hiperparámetros para Regresión Logística: {grid_search_lr.best_params_}\")\n",
    "    print(f\"Mejor ROC AUC (CV) para Regresión Logística: {grid_search_lr.best_score_:.4f}\")\n",
    "    best_lr_model = grid_search_lr.best_estimator_\n",
    "    y_pred_lr = best_lr_model.predict(X_test_cls)\n",
    "    y_proba_lr = best_lr_model.predict_proba(X_test_cls)[:, 1]\n",
    "\n",
    "    # --- Modelo 2: Random Forest Classifier ---\n",
    "    print(\"\\n--- Entrenando Random Forest Classifier ---\")\n",
    "    rf_class_weight = None\n",
    "    if 'imbalanced_target' in globals() and imbalanced_target:\n",
    "        rf_class_weight = 'balanced'\n",
    "\n",
    "    # Renombrar pipeline y grid_search para evitar colisiones con RandomForestRegressor\n",
    "    pipeline_rf_cls = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor_cls),\n",
    "        ('classifier', RandomForestClassifier(random_state=42,\n",
    "                                              class_weight=rf_class_weight))\n",
    "    ])\n",
    "\n",
    "    # Hiperparámetros para Random Forest\n",
    "    param_grid_rf_cls = { # Renombrado\n",
    "        'classifier__n_estimators': [100, 200],\n",
    "        'classifier__max_depth': [None, 10, 20],\n",
    "        'classifier__min_samples_split': [2, 5],\n",
    "    }\n",
    "\n",
    "    grid_search_rf_cls = GridSearchCV(pipeline_rf_cls, param_grid_rf_cls, cv=cv_stratified, scoring='roc_auc', n_jobs=-1, verbose=0)\n",
    "    grid_search_rf_cls.fit(X_train_cls, y_train_cls)\n",
    "\n",
    "    print(f\"Mejores hiperparámetros para Random Forest: {grid_search_rf_cls.best_params_}\")\n",
    "    print(f\"Mejor ROC AUC (CV) para Random Forest: {grid_search_rf_cls.best_score_:.4f}\")\n",
    "    best_rf_cls_model = grid_search_rf_cls.best_estimator_ # Renombrado\n",
    "    y_pred_rf_cls = best_rf_cls_model.predict(X_test_cls) # Renombrado\n",
    "    y_proba_rf_cls = best_rf_cls_model.predict_proba(X_test_cls)[:, 1] # Renombrado\n",
    "\n",
    "    # --- Evaluación Comparativa ---\n",
    "    print(\"\\n--- Evaluación en el Conjunto de Prueba ---\")\n",
    "    print(\"\\nRegresión Logística - Reporte de Clasificación:\")\n",
    "    print(classification_report(y_test_cls, y_pred_lr, target_names=['No Lluvia', 'Lluvia']))\n",
    "    print(f\"Regresión Logística - ROC AUC: {roc_auc_score(y_test_cls, y_proba_lr):.4f}\")\n",
    "\n",
    "    print(\"\\nRandom Forest - Reporte de Clasificación:\")\n",
    "    print(classification_report(y_test_cls, y_pred_rf_cls, target_names=['No Lluvia', 'Lluvia']))\n",
    "    print(f\"Random Forest - ROC AUC: {roc_auc_score(y_test_cls, y_proba_rf_cls):.4f}\")\n",
    "\n",
    "    # --- Matriz de Confusión ---\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    ConfusionMatrixDisplay.from_estimator(best_lr_model, X_test_cls, y_test_cls, ax=axes[0], display_labels=['No Lluvia', 'Lluvia'], cmap='Blues')\n",
    "    axes[0].set_title('Matriz de Confusión - Regresión Logística')\n",
    "\n",
    "    ConfusionMatrixDisplay.from_estimator(best_rf_cls_model, X_test_cls, y_test_cls, ax=axes[1], display_labels=['No Lluvia', 'Lluvia'], cmap='Greens')\n",
    "    axes[1].set_title('Matriz de Confusión - Random Forest')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # --- Curva ROC ---\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    fpr_lr, tpr_lr, _ = roc_curve(y_test_cls, y_proba_lr)\n",
    "    plt.plot(fpr_lr, tpr_lr, label=f\"Regresión Logística (AUC = {roc_auc_score(y_test_cls, y_proba_lr):.2f})\")\n",
    "    \n",
    "    fpr_rf, tpr_rf, _ = roc_curve(y_test_cls, y_proba_rf_cls)\n",
    "    plt.plot(fpr_rf, tpr_rf, label=f\"Random Forest (AUC = {roc_auc_score(y_test_cls, y_proba_rf_cls):.2f})\")\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--') # Línea de azar\n",
    "    plt.xlabel('Tasa de Falsos Positivos (FPR)')\n",
    "    plt.ylabel('Tasa de Verdaderos Positivos (TPR)')\n",
    "    plt.title('Curvas ROC Comparativas')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"Los datos de entrenamiento para clasificación (X_train_cls, y_train_cls) o el preprocesador (preprocessor_cls) no están disponibles. Modelado omitido.\")\n",
    "    # Definir variables para evitar errores en celdas posteriores si esta rama se ejecuta\n",
    "    best_lr_model, best_rf_cls_model = None, None\n",
    "    y_pred_lr, y_proba_lr, y_pred_rf_cls, y_proba_rf_cls = None, None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057927ef-a97f-478a-b58a-1dabd22813ce",
   "metadata": {},
   "source": [
    "### Celda 16: Modelado de Clasificación (RandomForest y Regresión Logística con `GridSearchCV`)\n",
    "\n",
    "**Propósito:** Entrenar, optimizar y evaluar modelos de Regresión Logística y Random Forest para predecir `RainTomorrow`.\n",
    "\n",
    "**Detalles del Código:**\n",
    "*   Se verifica que las variables necesarias (`X_train_cls`, `y_train_cls`, `preprocessor_cls`) existan.\n",
    "*   Se definen `Pipeline`s para cada modelo, incluyendo el `preprocessor_cls`.\n",
    "*   `class_weight='balanced'` se usa si la variable global `imbalanced_target` (definida en Celda 6 de EDA) es `True`.\n",
    "*   Se definen grillas de hiperparámetros (`param_grid_lr`, `param_grid_rf_cls`).\n",
    "*   `GridSearchCV` con `StratifiedKFold` (para mantener la proporción de clases en cada fold durante la validación cruzada) y `scoring='roc_auc'` encuentra los mejores modelos. Se renombraron algunas variables de Random Forest Classifier (`pipeline_rf_cls`, `best_rf_cls_model`, etc.) para evitar colisiones con los modelos de regresión que vendrán después.\n",
    "*   Se evalúan los modelos en el conjunto de prueba (`X_test_cls`, `y_test_cls`) usando `classification_report`, `roc_auc_score`.\n",
    "*   Se visualizan las matrices de confusión y las curvas ROC comparativas.\n",
    "*   Si los datos de entrenamiento no están disponibles, se omite el modelado y se definen las variables de modelo y predicción como `None`.\n",
    "\n",
    "**Resultado Esperado:**\n",
    "Si los datos están listos:\n",
    "*   Mejores hiperparámetros y scores de ROC AUC de validación cruzada para cada modelo.\n",
    "*   Reportes de clasificación detallados (precisión, recall, F1-score) para cada modelo en el conjunto de prueba.\n",
    "*   Valores de ROC AUC en el conjunto de prueba.\n",
    "*   Visualizaciones de las matrices de confusión y las curvas ROC.\n",
    "Si los datos no están listos, un mensaje indicando que se omitió el modelado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd4a3ca-dcbd-4c5c-9b89-ad02fc8d323f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Importancia de Características para el Mejor Random Forest Classifier ---\n",
    "if 'best_rf_cls_model' in globals() and best_rf_cls_model is not None and \\\n",
    "   'numerical_cols_cls' in globals() and 'categorical_cols_cls' in globals(): # Asegurar que estas listas existen\n",
    "    \n",
    "    preprocessor_fitted_cls = best_rf_cls_model.named_steps['preprocessor']\n",
    "    classifier_fitted_cls = best_rf_cls_model.named_steps['classifier']\n",
    "\n",
    "    try:\n",
    "        # 1. Obtener nombres de características numéricas\n",
    "        # Directamente de la lista original, ya que StandardScaler no cambia el número ni el orden.\n",
    "        num_feature_names_cls = numerical_cols_cls\n",
    "\n",
    "        # 2. Obtener nombres de características categóricas transformadas por OneHotEncoder\n",
    "        cat_pipeline_cls = preprocessor_fitted_cls.named_transformers_['cat']\n",
    "        onehot_encoder_cls = cat_pipeline_cls.named_steps['onehot']\n",
    "        \n",
    "        # Usar la lista original de columnas categóricas alimentada al ColumnTransformer\n",
    "        original_cat_cols_cls_from_transformer = categorical_cols_cls\n",
    "\n",
    "        if original_cat_cols_cls_from_transformer: # Si hay columnas categóricas\n",
    "             cat_feature_names_cls = list(onehot_encoder_cls.get_feature_names_out(original_cat_cols_cls_from_transformer))\n",
    "        else:\n",
    "            cat_feature_names_cls = []\n",
    "            \n",
    "        # Combinar todos los nombres de características en el orden correcto\n",
    "        all_feature_names_cls = list(num_feature_names_cls) + cat_feature_names_cls\n",
    "        \n",
    "        importances_cls = classifier_fitted_cls.feature_importances_\n",
    "\n",
    "        # Verificar que el número de importancias coincida con el número de nombres de características\n",
    "        if len(all_feature_names_cls) == len(importances_cls):\n",
    "            feature_importance_cls_df = pd.DataFrame({'feature': all_feature_names_cls, 'importance': importances_cls})\n",
    "            feature_importance_cls_df = feature_importance_cls_df.sort_values('importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "            N = 20 \n",
    "            plt.figure(figsize=(12, max(6, N*0.35))) \n",
    "            sns.barplot(x='importance', y='feature', data=feature_importance_cls_df.head(N), palette='viridis')\n",
    "            plt.title(f'Top {N} Características Más Importantes (Random Forest Classifier)', fontsize=16)\n",
    "            plt.xlabel('Importancia (Reducción Media de Impureza)', fontsize=12)\n",
    "            plt.ylabel('Característica', fontsize=12)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(f\"Error: El número de nombres de características ({len(all_feature_names_cls)}) no coincide con el número de importancias ({len(importances_cls)}).\")\n",
    "            print(\"Nombres de características numéricas:\", num_feature_names_cls)\n",
    "            print(\"Nombres de características categóricas (transformadas):\", cat_feature_names_cls)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error al generar importancia de características para RF Classifier: {e}\")\n",
    "        print(\"Verifique que 'numerical_cols_cls' y 'categorical_cols_cls' estén correctamente definidos y que el preprocesador se ajustó correctamente.\")\n",
    "else:\n",
    "    print(\"El modelo Random Forest Classifier (best_rf_cls_model) no está definido, no se entrenó, o faltan listas de columnas (numerical_cols_cls/categorical_cols_cls).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe74ae7-a340-416c-be09-9971b9aa3927",
   "metadata": {},
   "source": [
    "### Celda 17: Importancia de Características para Random Forest Classifier\n",
    "\n",
    "**Propósito:** Visualizar las características más influyentes para el modelo `RandomForestClassifier` optimizado.\n",
    "\n",
    "**Detalles del Código:**\n",
    "*   Se verifica que el modelo `best_rf_cls_model` y las listas `numerical_cols_cls` y `categorical_cols_cls` existan.\n",
    "*   Se accede al preprocesador (`preprocessor_fitted_cls`) y al clasificador (`classifier_fitted_cls`) ajustados desde el pipeline.\n",
    "*   Se obtienen los nombres de las características numéricas directamente de `numerical_cols_cls`.\n",
    "*   Para las características categóricas, se utiliza `get_feature_names_out` del `OneHotEncoder` (que está dentro de un pipeline anidado en el `ColumnTransformer`) aplicado a la lista original `categorical_cols_cls`.\n",
    "*   Se combinan los nombres de las características numéricas y categóricas transformadas.\n",
    "*   Se extraen las `feature_importances_` del clasificador Random Forest.\n",
    "*   Se realiza una verificación para asegurar que el número de nombres de características coincida con el número de valores de importancia.\n",
    "*   Se crea un DataFrame y se visualizan las `N` características más importantes usando un gráfico de barras horizontales.\n",
    "*   Se incluye un manejo de errores más detallado.\n",
    "\n",
    "**Resultado Esperado:**\n",
    "Si el modelo se entrenó correctamente y las listas de columnas están disponibles:\n",
    "*   Un gráfico de barras mostrando las `N` características más importantes según el modelo Random Forest Classifier para la predicción de `RainTomorrow`.\n",
    "Si hay problemas, se mostrarán mensajes de error o advertencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdae60b-dcb3-425d-8ed5-0589cfad792d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Preparación de Datos para Modelado de Regresión (Predecir MaxTemp y Rainfall) ---\n",
    "\n",
    "# Inicializar variables para evitar errores si gdf no existe o hay problemas\n",
    "X_train_reg_temp, X_test_reg_temp, y_train_reg_temp, y_test_reg_temp = [None]*4\n",
    "X_train_reg_rain, X_test_reg_rain, y_train_reg_rain, y_test_reg_rain = [None]*4\n",
    "preprocessor_reg_temp, preprocessor_reg_rain = None, None\n",
    "numerical_cols_reg_temp, categorical_cols_reg_temp = [], []\n",
    "numerical_cols_reg_rain, categorical_cols_reg_rain = [], []\n",
    "y_train_reg_rain_log = None # Para la transformación log de y_train_reg_rain\n",
    "\n",
    "\n",
    "if 'gdf' in globals() and gdf is not None:\n",
    "    df_reg = gdf.copy()\n",
    "\n",
    "    # --- 1. Codificación Binaria (si es necesario) ---\n",
    "    if 'RainToday' in df_reg.columns:\n",
    "        if df_reg['RainToday'].dtype == 'object':\n",
    "            df_reg.loc[:, 'RainToday'] = df_reg['RainToday'].map({'No': 0, 'Yes': 1}).astype(int)\n",
    "        elif pd.api.types.is_numeric_dtype(df_reg['RainToday']): # Ensure it's int if already numeric\n",
    "            df_reg.loc[:, 'RainToday'] = df_reg['RainToday'].astype(int)\n",
    "\n",
    "    # --- 2. Selección de Características (Features) ---\n",
    "    intended_base_features_reg = ['MinTemp', 'Humidity9am', 'Humidity3pm', 'WindGustSpeed',\n",
    "                             'Pressure9am', 'Pressure3pm', 'Temp9am', 'Temp3pm',\n",
    "                             'WindSpeed9am', 'WindSpeed3pm', 'DayOfYear',\n",
    "                             'RainToday', 'Season', 'WindGustDir', 'WindDir9am', 'WindDir3pm']\n",
    "    \n",
    "    # Asegurar que todas las features base existen en df_reg\n",
    "    base_features_reg = [col for col in intended_base_features_reg if col in df_reg.columns]\n",
    "    \n",
    "    # --- Para predecir MaxTemp ---\n",
    "    target_temp = 'MaxTemp'\n",
    "    # Start with base features, exclude the target\n",
    "    features_reg_temp_candidate = [f for f in base_features_reg if f != target_temp]\n",
    "    # Asegurar que Rainfall (de hoy) esté como predictor para MaxTemp (de hoy)\n",
    "    if 'Rainfall' not in features_reg_temp_candidate and 'Rainfall' in df_reg.columns:\n",
    "        features_reg_temp_candidate.append('Rainfall')\n",
    "    # Filtrar nuevamente para asegurar que todas las características seleccionadas existan en df_reg\n",
    "    features_reg_temp = list(set(f for f in features_reg_temp_candidate if f in df_reg.columns))\n",
    "\n",
    "    X_reg_temp, y_reg_temp = None, None\n",
    "    if target_temp in df_reg.columns and features_reg_temp:\n",
    "        print(f\"Características seleccionadas para regresión (MaxTemp): {features_reg_temp}\")\n",
    "        X_reg_temp = df_reg[features_reg_temp].copy() # Use .copy()\n",
    "        y_reg_temp = df_reg[target_temp].copy()\n",
    "    else:\n",
    "        print(f\"ERROR: No se puede preparar datos para regresión de MaxTemp (target '{target_temp}' o features faltantes/vacías).\")\n",
    "\n",
    "    # --- Para predecir Rainfall ---\n",
    "    target_rain = 'Rainfall'\n",
    "    features_reg_rain_candidate = [f for f in base_features_reg if f != target_rain]\n",
    "    if 'MaxTemp' not in features_reg_rain_candidate and 'MaxTemp' in df_reg.columns:\n",
    "        features_reg_rain_candidate.append('MaxTemp')\n",
    "    features_reg_rain = list(set(f for f in features_reg_rain_candidate if f in df_reg.columns))\n",
    "    \n",
    "    X_reg_rain, y_reg_rain = None, None\n",
    "    if target_rain in df_reg.columns and features_reg_rain:\n",
    "        print(f\"Características seleccionadas para regresión (Rainfall): {features_reg_rain}\")\n",
    "        X_reg_rain = df_reg[features_reg_rain].copy() # Use .copy()\n",
    "        y_reg_rain = df_reg[target_rain].copy()\n",
    "    else:\n",
    "        print(f\"ERROR: No se puede preparar datos para regresión de Rainfall (target '{target_rain}' o features faltantes/vacías).\")\n",
    "\n",
    "    # --- 3 & 4. Definir Preprocesadores y Dividir Datos ---\n",
    "    reg_numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='mean')), ('scaler', StandardScaler())])\n",
    "    reg_categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')), ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))])\n",
    "\n",
    "    # Preprocesador para MaxTemp\n",
    "    if X_reg_temp is not None and y_reg_temp is not None:\n",
    "        numerical_cols_reg_temp = []\n",
    "        categorical_cols_reg_temp = []\n",
    "        for col in X_reg_temp.columns:\n",
    "            if pd.api.types.is_numeric_dtype(X_reg_temp[col]):\n",
    "                numerical_cols_reg_temp.append(col)\n",
    "            else:\n",
    "                categorical_cols_reg_temp.append(col)\n",
    "        \n",
    "        print(f\"\\nPara MaxTemp - Características numéricas: {numerical_cols_reg_temp}\")\n",
    "        print(f\"Para MaxTemp - Características categóricas: {categorical_cols_reg_temp}\")\n",
    "\n",
    "        transformers_list_temp = []\n",
    "        if numerical_cols_reg_temp:\n",
    "            transformers_list_temp.append(('num', reg_numeric_transformer, numerical_cols_reg_temp))\n",
    "        if categorical_cols_reg_temp:\n",
    "            transformers_list_temp.append(('cat', reg_categorical_transformer, categorical_cols_reg_temp))\n",
    "\n",
    "        if not transformers_list_temp:\n",
    "            print(\"ERROR (MaxTemp): No hay transformadores definidos.\")\n",
    "            preprocessor_reg_temp = None\n",
    "        else:\n",
    "            preprocessor_reg_temp = ColumnTransformer(\n",
    "                transformers=transformers_list_temp,\n",
    "                remainder='drop' # Crucial: drop unhandled columns\n",
    "            )\n",
    "            X_train_reg_temp, X_test_reg_temp, y_train_reg_temp, y_test_reg_temp = train_test_split(\n",
    "                X_reg_temp, y_reg_temp, test_size=0.25, random_state=42)\n",
    "            print(f\"Dimensiones X_train_reg_temp: {X_train_reg_temp.shape if X_train_reg_temp is not None else 'N/A'}\")\n",
    "\n",
    "    # Preprocesador para Rainfall\n",
    "    if X_reg_rain is not None and y_reg_rain is not None:\n",
    "        numerical_cols_reg_rain = []\n",
    "        categorical_cols_reg_rain = []\n",
    "        for col in X_reg_rain.columns:\n",
    "            if pd.api.types.is_numeric_dtype(X_reg_rain[col]):\n",
    "                numerical_cols_reg_rain.append(col)\n",
    "            else:\n",
    "                categorical_cols_reg_rain.append(col)\n",
    "\n",
    "        print(f\"\\nPara Rainfall - Características numéricas: {numerical_cols_reg_rain}\")\n",
    "        print(f\"Para Rainfall - Características categóricas: {categorical_cols_reg_rain}\")\n",
    "        \n",
    "        transformers_list_rain = []\n",
    "        if numerical_cols_reg_rain:\n",
    "            transformers_list_rain.append(('num', reg_numeric_transformer, numerical_cols_reg_rain))\n",
    "        if categorical_cols_reg_rain:\n",
    "            transformers_list_rain.append(('cat', reg_categorical_transformer, categorical_cols_reg_rain))\n",
    "\n",
    "        if not transformers_list_rain:\n",
    "            print(\"ERROR (Rainfall): No hay transformadores definidos.\")\n",
    "            preprocessor_reg_rain = None\n",
    "        else:\n",
    "            preprocessor_reg_rain = ColumnTransformer(\n",
    "                transformers=transformers_list_rain,\n",
    "                remainder='drop' # Crucial: drop unhandled columns\n",
    "            )\n",
    "            X_train_reg_rain, X_test_reg_rain, y_train_reg_rain, y_test_reg_rain = train_test_split(\n",
    "                X_reg_rain, y_reg_rain, test_size=0.25, random_state=42)\n",
    "            \n",
    "            if y_train_reg_rain is not None: # Asegurarse que y_train_reg_rain existe antes de transformarlo\n",
    "                y_train_reg_rain_log = np.log1p(y_train_reg_rain)\n",
    "            print(f\"Dimensiones X_train_reg_rain: {X_train_reg_rain.shape if X_train_reg_rain is not None else 'N/A'}\")\n",
    "else:\n",
    "    print(\"GeoDataFrame (gdf) no está disponible, no se puede preparar datos para ML de regresión.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e2f9fd-6ddc-4ebb-abb3-b1d6070a4e24",
   "metadata": {},
   "source": [
    "### Celda 18: Preparación de Datos para Modelado de Regresión (`MaxTemp` y `Rainfall`)\n",
    "\n",
    "**Propósito:** Preparar los datos para dos tareas de regresión distintas: predecir la temperatura máxima (`MaxTemp`) y la cantidad de lluvia (`Rainfall`).\n",
    "\n",
    "**Detalles del Código:**\n",
    "1.  **Inicialización:** Las variables clave para los datos de regresión (`X_train_reg_temp`, `preprocessor_reg_temp`, etc.) se inicializan a `None` o listas vacías. Esto es para evitar errores `NameError` en celdas posteriores si `gdf` no existe o si la preparación de datos para una de las tareas falla.\n",
    "2.  **Copia y Codificación:** Si `gdf` existe, se crea `df_reg`. La columna `RainToday` se codifica a 0/1 si es de tipo objeto.\n",
    "3.  **Selección de Características Base:** Se define `base_features_reg` con un conjunto de predictores potenciales. Se filtran para asegurar que solo las columnas existentes en `df_reg` se consideren.\n",
    "4.  **Preparación para `MaxTemp`:**\n",
    "    *   `target_temp` es 'MaxTemp'.\n",
    "    *   `features_reg_temp_candidate` se crea excluyendo `target_temp` de `base_features_reg`.\n",
    "    *   Se asegura que 'Rainfall' (lluvia de hoy) se incluya como predictor para 'MaxTemp' (temperatura máxima de hoy).\n",
    "    *   `features_reg_temp` se finaliza filtrando nuevamente para asegurar que todas las características existan.\n",
    "    *   Se crean `X_reg_temp` e `y_reg_temp` si el target y las features son válidos.\n",
    "5.  **Preparación para `Rainfall`:**\n",
    "    *   `target_rain` es 'Rainfall'.\n",
    "    *   `features_reg_rain_candidate` se crea excluyendo `target_rain`.\n",
    "    *   Se asegura que 'MaxTemp' (temperatura máxima de hoy) se incluya como predictor para 'Rainfall' (lluvia de hoy).\n",
    "    *   `features_reg_rain` se finaliza con un filtro de existencia.\n",
    "    *   Se crean `X_reg_rain` e `y_reg_rain` si son válidos.\n",
    "6.  **Preprocesadores y División de Datos:**\n",
    "    *   Se definen transformadores comunes (`reg_numeric_transformer`, `reg_categorical_transformer`).\n",
    "    *   Si `X_reg_temp` e `y_reg_temp` se crearon con éxito:\n",
    "        *   Se identifican `numerical_cols_reg_temp` y `categorical_cols_reg_temp`.\n",
    "        *   Se define `preprocessor_reg_temp`.\n",
    "        *   Se realiza el `train_test_split`.\n",
    "    *   Se repite un proceso similar para `X_reg_rain` e `y_reg_rain`, creando `preprocessor_reg_rain` y los conjuntos de datos correspondientes.\n",
    "    *   **Importante:** `y_train_reg_rain_log` se crea aplicando `np.log1p` a `y_train_reg_rain` aquí, ya que el modelo de lluvia se entrenará con la variable objetivo transformada.\n",
    "\n",
    "**Resultado Esperado:**\n",
    "*   Mensajes de estado indicando la preparación de datos para cada tarea de regresión.\n",
    "*   Listas de características numéricas y categóricas para cada tarea.\n",
    "*   Dimensiones de los conjuntos de entrenamiento `X_train_reg_temp` y `X_train_reg_rain`.\n",
    "*   Mensajes de error si los targets o las features no se pueden definir correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eb47b5-9a4c-4e8c-ba66-2661f79e3712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Modelo de Regresión para MaxTemp con RandomForestRegressor y Optimización ---\n",
    "\n",
    "# Inicializar métricas y modelo para evitar errores si no se ejecuta\n",
    "r2_temp, rmse_temp = np.nan, np.nan\n",
    "best_rf_temp_model = None\n",
    "y_pred_reg_temp = None # Para el gráfico de predicción vs real\n",
    "\n",
    "if 'X_train_reg_temp' in globals() and X_train_reg_temp is not None and \\\n",
    "   'y_train_reg_temp' in globals() and y_train_reg_temp is not None and \\\n",
    "   'preprocessor_reg_temp' in globals() and preprocessor_reg_temp is not None:\n",
    "    \n",
    "    print(\"--- Entrenando RandomForestRegressor para MaxTemp ---\")\n",
    "    \n",
    "    pipeline_rf_temp = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor_reg_temp),\n",
    "        ('regressor', RandomForestRegressor(random_state=42))])\n",
    "\n",
    "    # Usar un rango de hiperparámetros consistente, puede ser el mismo que el de clasificación de RF si aplica, o ajustado\n",
    "    param_grid_rf_reg = {\n",
    "        'regressor__n_estimators': [100, 150],       # Reducido para velocidad en demostración\n",
    "        'regressor__max_depth': [10, 20, None],      # None para permitir crecimiento completo\n",
    "        'regressor__min_samples_split': [2, 5],\n",
    "        'regressor__min_samples_leaf': [1, 2]        # Añadido para regularización\n",
    "    }\n",
    "    # KFold normal para regresión (StratifiedKFold es para clasificación)\n",
    "    cv_kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    grid_search_rf_temp = GridSearchCV(pipeline_rf_temp, param_grid_rf_reg, cv=cv_kfold, scoring='r2', n_jobs=-1, verbose=0)\n",
    "    grid_search_rf_temp.fit(X_train_reg_temp, y_train_reg_temp)\n",
    "\n",
    "    print(f\"Mejores hiperparámetros para RFR (MaxTemp): {grid_search_rf_temp.best_params_}\")\n",
    "    print(f\"Mejor R² (CV) para RFR (MaxTemp): {grid_search_rf_temp.best_score_:.4f}\")\n",
    "    \n",
    "    best_rf_temp_model = grid_search_rf_temp.best_estimator_\n",
    "    y_pred_reg_temp = best_rf_temp_model.predict(X_test_reg_temp)\n",
    "\n",
    "    # Métricas de Evaluación\n",
    "    r2_temp = r2_score(y_test_reg_temp, y_pred_reg_temp)\n",
    "    rmse_temp = mean_squared_error(y_test_reg_temp, y_pred_reg_temp, squared=False)\n",
    "\n",
    "    print(\"\\nRandomForestRegressor – Predicción de MaxTemp:\")\n",
    "    print(f\"  R² en conjunto de prueba: {r2_temp:.3f}\")\n",
    "    print(f\"  RMSE en conjunto de prueba: {rmse_temp:.2f}°C\")\n",
    "\n",
    "    # --- Importancia de Características para RFR (MaxTemp) ---\n",
    "    if best_rf_temp_model is not None and \\\n",
    "       'numerical_cols_reg_temp' in globals() and 'categorical_cols_reg_temp' in globals():\n",
    "        try:\n",
    "            preprocessor_fitted_temp = best_rf_temp_model.named_steps['preprocessor']\n",
    "            regressor_fitted_temp = best_rf_temp_model.named_steps['regressor']\n",
    "            \n",
    "            num_feat_names_temp = numerical_cols_reg_temp\n",
    "            \n",
    "            cat_pipeline_temp = preprocessor_fitted_temp.named_transformers_['cat']\n",
    "            onehot_encoder_temp = cat_pipeline_temp.named_steps['onehot']\n",
    "            original_cat_cols_temp_transformer = categorical_cols_reg_temp\n",
    "\n",
    "            if original_cat_cols_temp_transformer:\n",
    "                 cat_feat_names_temp = list(onehot_encoder_temp.get_feature_names_out(original_cat_cols_temp_transformer))\n",
    "            else:\n",
    "                cat_feat_names_temp = []\n",
    "                \n",
    "            all_feat_names_temp = list(num_feat_names_temp) + cat_feat_names_temp\n",
    "            \n",
    "            importances_temp = regressor_fitted_temp.feature_importances_\n",
    "\n",
    "            if len(all_feat_names_temp) == len(importances_temp):\n",
    "                feature_importance_temp_df = pd.DataFrame({'feature': all_feat_names_temp, 'importance': importances_temp})\n",
    "                feature_importance_temp_df = feature_importance_temp_df.sort_values('importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "                N = 15\n",
    "                plt.figure(figsize=(10, max(5, N*0.35)))\n",
    "                sns.barplot(x='importance', y='feature', data=feature_importance_temp_df.head(N), palette='mako')\n",
    "                plt.title(f'Top {N} Características - Predicción MaxTemp (RFR)', fontsize=16)\n",
    "                plt.xlabel('Importancia', fontsize=12)\n",
    "                plt.ylabel('Característica', fontsize=12)\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "            else:\n",
    "                print(f\"Error en feat. imp. (MaxTemp): Nombres ({len(all_feat_names_temp)}) vs Importancias ({len(importances_temp)}).\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error al generar importancia de características para RFR (MaxTemp): {e}\")\n",
    "else:\n",
    "    print(\"Los datos de entrenamiento/preprocesador para regresión de MaxTemp no están disponibles. Modelado omitido.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5511513-0c2d-4465-bb20-220b8b37ea6e",
   "metadata": {},
   "source": [
    "### Celda 19: Modelo de Regresión para `MaxTemp` (RandomForestRegressor con `GridSearchCV`)\n",
    "\n",
    "**Propósito:** Entrenar, optimizar y evaluar un modelo `RandomForestRegressor` para predecir la temperatura máxima (`MaxTemp`).\n",
    "\n",
    "**Detalles del Código:**\n",
    "1.  **Inicialización:** `r2_temp`, `rmse_temp`, `best_rf_temp_model`, y `y_pred_reg_temp` se inicializan para evitar errores si el modelado se omite.\n",
    "2.  **Verificación:** Se comprueba que los datos de entrenamiento (`X_train_reg_temp`, `y_train_reg_temp`) y el preprocesador (`preprocessor_reg_temp`) estén disponibles.\n",
    "3.  **Pipeline y GridSearchCV:**\n",
    "    *   Se crea una `Pipeline` con el `preprocessor_reg_temp` y un `RandomForestRegressor`.\n",
    "    *   Se define `param_grid_rf_reg` para los hiperparámetros del regresor (incluyendo `min_samples_leaf` para regularización).\n",
    "    *   `GridSearchCV` con `KFold` (adecuado para regresión) y `scoring='r2'` se utiliza para encontrar el mejor modelo.\n",
    "4.  **Evaluación:**\n",
    "    *   El mejor modelo se usa para predecir en `X_test_reg_temp`.\n",
    "    *   Se calculan y muestran R² y RMSE (Error Cuadrático Medio Raíz).\n",
    "5.  **Importancia de Características:**\n",
    "    *   Se extraen y visualizan las importancias de las características del `RandomForestRegressor` entrenado, de manera similar a como se hizo para el clasificador. Se verifica que las listas `numerical_cols_reg_temp` y `categorical_cols_reg_temp` existan.\n",
    "    *   Se incluye una comprobación de la longitud de los nombres de características y las importancias.\n",
    "\n",
    "**Resultado Esperado:**\n",
    "Si los datos están listos:\n",
    "*   Mejores hiperparámetros y R² de validación cruzada para el `RandomForestRegressor`.\n",
    "*   Métricas R² y RMSE en el conjunto de prueba para la predicción de `MaxTemp`.\n",
    "*   Un gráfico de barras mostrando las características más importantes para predecir `MaxTemp`.\n",
    "Si los datos no están listos, un mensaje indicando que se omitió el modelado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83262c8d-56fa-4d9f-9442-3919e128eeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Modelo de Regresión para Rainfall con RandomForestRegressor, Log-Transform y Optimización ---\n",
    "\n",
    "# Inicializar métricas y modelo\n",
    "r2_rain, rmse_rain = np.nan, np.nan\n",
    "best_rf_rain_model = None\n",
    "y_pred_reg_rain = None # Para el gráfico de predicción vs real\n",
    "\n",
    "if 'X_train_reg_rain' in globals() and X_train_reg_rain is not None and \\\n",
    "   'y_train_reg_rain_log' in globals() and y_train_reg_rain_log is not None and \\\n",
    "   'y_test_reg_rain' in globals() and y_test_reg_rain is not None and \\\n",
    "   'preprocessor_reg_rain' in globals() and preprocessor_reg_rain is not None:\n",
    "    \n",
    "    print(\"--- Entrenando RandomForestRegressor para Rainfall (con Log-Transform) ---\")\n",
    "    \n",
    "    # y_train_reg_rain_log ya debería estar calculado en la celda de preparación de datos de regresión.\n",
    "    \n",
    "    pipeline_rf_rain = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor_reg_rain), # Usar el preprocesador específico para Rainfall\n",
    "        ('regressor', RandomForestRegressor(random_state=42))\n",
    "    ])\n",
    "\n",
    "    # Reutilizar param_grid_rf_reg (definido para MaxTemp RFR) o definir uno nuevo si es necesario\n",
    "    # Para este ejemplo, lo reutilizamos.\n",
    "    if 'param_grid_rf_reg' not in globals(): # Definir si no existe globalmente\n",
    "        param_grid_rf_reg = {\n",
    "            'regressor__n_estimators': [100, 150],\n",
    "            'regressor__max_depth': [10, 20, None],\n",
    "            'regressor__min_samples_split': [2, 5],\n",
    "            'regressor__min_samples_leaf': [1, 2]\n",
    "        }\n",
    "    if 'cv_kfold' not in globals(): # Definir si no existe globalmente\n",
    "        cv_kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    grid_search_rf_rain = GridSearchCV(pipeline_rf_rain, param_grid_rf_reg, cv=cv_kfold, scoring='r2', n_jobs=-1, verbose=0)\n",
    "    grid_search_rf_rain.fit(X_train_reg_rain, y_train_reg_rain_log) # Entrenar con y_log\n",
    "\n",
    "    print(f\"Mejores hiperparámetros para RFR (Rainfall): {grid_search_rf_rain.best_params_}\")\n",
    "    print(f\"Mejor R² (CV) para RFR (Rainfall en escala log): {grid_search_rf_rain.best_score_:.4f}\")\n",
    "    \n",
    "    best_rf_rain_model = grid_search_rf_rain.best_estimator_\n",
    "    y_pred_reg_rain_log = best_rf_rain_model.predict(X_test_reg_rain)\n",
    "\n",
    "    # Inversión de la transformación logarítmica para obtener predicciones en la escala original\n",
    "    y_pred_reg_rain = np.expm1(y_pred_reg_rain_log)\n",
    "    # Asegurar que las predicciones no sean negativas (la lluvia no puede ser negativa)\n",
    "    y_pred_reg_rain = np.maximum(0, y_pred_reg_rain)\n",
    "\n",
    "    # Métricas de Evaluación (en la escala original)\n",
    "    r2_rain = r2_score(y_test_reg_rain, y_pred_reg_rain)\n",
    "    rmse_rain = mean_squared_error(y_test_reg_rain, y_pred_reg_rain, squared=False)\n",
    "\n",
    "    print(\"\\nRandomForestRegressor – Predicción de Rainfall (evaluado en escala original):\")\n",
    "    print(f\"  R² en conjunto de prueba: {r2_rain:.3f}\")\n",
    "    print(f\"  RMSE en conjunto de prueba: {rmse_rain:.2f} mm\")\n",
    "\n",
    "    # --- Importancia de Características para RFR (Rainfall) ---\n",
    "    if best_rf_rain_model is not None and \\\n",
    "       'numerical_cols_reg_rain' in globals() and 'categorical_cols_reg_rain' in globals():\n",
    "        try:\n",
    "            preprocessor_fitted_rain = best_rf_rain_model.named_steps['preprocessor']\n",
    "            regressor_fitted_rain = best_rf_rain_model.named_steps['regressor']\n",
    "\n",
    "            num_feat_names_rain = numerical_cols_reg_rain\n",
    "            \n",
    "            cat_pipeline_rain = preprocessor_fitted_rain.named_transformers_['cat']\n",
    "            onehot_encoder_rain = cat_pipeline_rain.named_steps['onehot']\n",
    "            original_cat_cols_rain_transformer = categorical_cols_reg_rain\n",
    "\n",
    "            if original_cat_cols_rain_transformer:\n",
    "                cat_feat_names_rain = list(onehot_encoder_rain.get_feature_names_out(original_cat_cols_rain_transformer))\n",
    "            else:\n",
    "                cat_feat_names_rain = []\n",
    "                \n",
    "            all_feat_names_rain = list(num_feat_names_rain) + cat_feat_names_rain\n",
    "            \n",
    "            importances_rain = regressor_fitted_rain.feature_importances_\n",
    "\n",
    "            if len(all_feat_names_rain) == len(importances_rain):\n",
    "                feature_importance_rain_df = pd.DataFrame({'feature': all_feat_names_rain, 'importance': importances_rain})\n",
    "                feature_importance_rain_df = feature_importance_rain_df.sort_values('importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "                N = 15\n",
    "                plt.figure(figsize=(10, max(5, N*0.35)))\n",
    "                sns.barplot(x='importance', y='feature', data=feature_importance_rain_df.head(N), palette='crest')\n",
    "                plt.title(f'Top {N} Características - Predicción Rainfall (RFR)', fontsize=16)\n",
    "                plt.xlabel('Importancia', fontsize=12)\n",
    "                plt.ylabel('Característica', fontsize=12)\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "            else:\n",
    "                print(f\"Error en feat. imp. (Rainfall): Nombres ({len(all_feat_names_rain)}) vs Importancias ({len(importances_rain)}).\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al generar importancia de características para RFR (Rainfall): {e}\")\n",
    "else:\n",
    "    print(\"Los datos de entrenamiento/preprocesador para regresión de Rainfall no están disponibles. Modelado omitido.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309be5e2-f9e5-40fc-95fa-d84f1f3611f5",
   "metadata": {},
   "source": [
    "### Celda 20: Modelo de Regresión para `Rainfall` (RandomForestRegressor con Log-Transform y `GridSearchCV`)\n",
    "\n",
    "**Propósito:** Entrenar, optimizar y evaluar un modelo `RandomForestRegressor` para predecir la cantidad de lluvia (`Rainfall`). Dado que `Rainfall` es una variable con asimetría positiva (muchos ceros y algunos valores altos), se aplica una transformación logarítmica a la variable objetivo.\n",
    "\n",
    "**Detalles del Código:**\n",
    "1.  **Inicialización:** `r2_rain`, `rmse_rain`, `best_rf_rain_model`, y `y_pred_reg_rain` se inicializan.\n",
    "2.  **Verificación:** Se comprueba que los datos de entrenamiento (`X_train_reg_rain`, `y_train_reg_rain_log`), el conjunto de prueba `y_test_reg_rain` (para evaluación final en escala original), y el preprocesador (`preprocessor_reg_rain`) estén disponibles.\n",
    "3.  **Transformación Logarítmica:** `y_train_reg_rain_log` (que se calculó en la celda de preparación de datos de regresión usando `np.log1p`) se utiliza para entrenar el modelo.\n",
    "4.  **Pipeline y GridSearchCV:**\n",
    "    *   Se crea una `Pipeline` con `preprocessor_reg_rain` y `RandomForestRegressor`.\n",
    "    *   Se reutiliza `param_grid_rf_reg` y `cv_kfold` (definidos previamente para el regresor de `MaxTemp`) o se definen si no existen.\n",
    "    *   `GridSearchCV` se ajusta usando `y_train_reg_rain_log`.\n",
    "5.  **Predicción e Inversión de Transformación:**\n",
    "    *   Las predicciones (`y_pred_reg_rain_log`) se hacen en la escala logarítmica.\n",
    "    *   `np.expm1` se usa para invertir la transformación y obtener `y_pred_reg_rain` en la escala original (mm).\n",
    "    *   Se asegura que las predicciones de lluvia no sean negativas usando `np.maximum(0, ...)`.\n",
    "6.  **Evaluación:** R² y RMSE se calculan comparando `y_test_reg_rain` (valores reales en escala original) con `y_pred_reg_rain`.\n",
    "7.  **Importancia de Características:** Similar al modelo de `MaxTemp`, se visualizan las características más importantes para predecir `Rainfall`.\n",
    "\n",
    "**Resultado Esperado:**\n",
    "Si los datos están listos:\n",
    "*   Mejores hiperparámetros y R² de validación cruzada (en escala logarítmica) para el `RandomForestRegressor` de `Rainfall`.\n",
    "*   Métricas R² y RMSE en el conjunto de prueba, evaluadas en la escala original de `Rainfall`.\n",
    "*   Un gráfico de barras mostrando las características más importantes para predecir `Rainfall`.\n",
    "Si los datos no están listos, un mensaje indicando que se omitió el modelado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d1b81a-bcdc-4a43-882b-633ec2bd6ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Modelado con XGBoost (si está disponible) ---\n",
    "\n",
    "# Inicializar variables para evitar errores si XGBoost no se ejecuta o falla\n",
    "y_pred_xgb_temp, y_pred_xgb_rain = None, None\n",
    "best_xgb_temp_model, best_xgb_rain_model = None, None\n",
    "\n",
    "if xgb_available:\n",
    "    print(\"✅ XGBoost está disponible. Entrenando modelos XGBoost...\\n\")\n",
    "\n",
    "    # --- XGBoost para MaxTemp ---\n",
    "    if 'X_train_reg_temp' in globals() and X_train_reg_temp is not None and \\\n",
    "       'y_train_reg_temp' in globals() and y_train_reg_temp is not None and \\\n",
    "       'preprocessor_reg_temp' in globals() and preprocessor_reg_temp is not None:\n",
    "        \n",
    "        print(\"--- Entrenando XGBRegressor para MaxTemp ---\")\n",
    "        pipeline_xgb_temp = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor_reg_temp),\n",
    "            ('regressor', XGBRegressor(objective='reg:squarederror', random_state=42, \n",
    "                                       n_estimators=100, learning_rate=0.1,\n",
    "                                       # Parámetros para evitar warnings comunes con versiones recientes\n",
    "                                       # tree_method='hist', enable_categorical=True # si se usan cats directamente en XGB\n",
    "                                      ))\n",
    "        ])\n",
    "        \n",
    "        # Hiperparámetros para XGBRegressor (un conjunto pequeño para demostración)\n",
    "        param_grid_xgb = {\n",
    "            'regressor__n_estimators': [100, 150], # Reducido para demostración\n",
    "            'regressor__learning_rate': [0.05, 0.1, 0.2],\n",
    "            'regressor__max_depth': [3, 5, 7]\n",
    "        }\n",
    "        if 'cv_kfold' not in globals(): # Definir si no existe globalmente\n",
    "            cv_kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "        grid_search_xgb_temp = GridSearchCV(pipeline_xgb_temp, param_grid_xgb, cv=cv_kfold, scoring='r2', n_jobs=-1, verbose=0)\n",
    "        grid_search_xgb_temp.fit(X_train_reg_temp, y_train_reg_temp)\n",
    "        \n",
    "        print(f\"Mejores hiperparámetros XGB (MaxTemp): {grid_search_xgb_temp.best_params_}\")\n",
    "        best_xgb_temp_model = grid_search_xgb_temp.best_estimator_\n",
    "        y_pred_xgb_temp = best_xgb_temp_model.predict(X_test_reg_temp)\n",
    "\n",
    "        print(\"\\nXGBoost – Predicción de MaxTemp:\")\n",
    "        print(f\"  R² (CV): {grid_search_xgb_temp.best_score_:.3f}\")\n",
    "        print(f\"  R² (Test): {r2_score(y_test_reg_temp, y_pred_xgb_temp):.3f}\")\n",
    "        print(f\"  RMSE (Test): {mean_squared_error(y_test_reg_temp, y_pred_xgb_temp, squared=False):.2f}°C\")\n",
    "    else:\n",
    "        print(\"Datos para XGBoost (MaxTemp) no disponibles. Modelado omitido.\")\n",
    "\n",
    "    # --- XGBoost para Rainfall (con Log-Transform) ---\n",
    "    if 'X_train_reg_rain' in globals() and X_train_reg_rain is not None and \\\n",
    "       'y_train_reg_rain_log' in globals() and y_train_reg_rain_log is not None and \\\n",
    "       'y_test_reg_rain' in globals() and y_test_reg_rain is not None and \\\n",
    "       'preprocessor_reg_rain' in globals() and preprocessor_reg_rain is not None:\n",
    "        \n",
    "        print(\"\\n--- Entrenando XGBRegressor para Rainfall (con Log-Transform) ---\")\n",
    "        pipeline_xgb_rain = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor_reg_rain),\n",
    "            ('regressor', XGBRegressor(objective='reg:squarederror', random_state=42,\n",
    "                                       n_estimators=100, learning_rate=0.1,\n",
    "                                       # tree_method='hist', enable_categorical=True\n",
    "                                      ))\n",
    "        ])\n",
    "        \n",
    "        # Reutilizar param_grid_xgb (definido arriba)\n",
    "        grid_search_xgb_rain = GridSearchCV(pipeline_xgb_rain, param_grid_xgb, cv=cv_kfold, scoring='r2', n_jobs=-1, verbose=0)\n",
    "        grid_search_xgb_rain.fit(X_train_reg_rain, y_train_reg_rain_log) # Entrenar con y_log\n",
    "\n",
    "        print(f\"Mejores hiperparámetros XGB (Rainfall): {grid_search_xgb_rain.best_params_}\")\n",
    "        best_xgb_rain_model = grid_search_xgb_rain.best_estimator_\n",
    "        y_pred_xgb_rain_log = best_xgb_rain_model.predict(X_test_reg_rain)\n",
    "        \n",
    "        y_pred_xgb_rain = np.expm1(y_pred_xgb_rain_log) # Invertir log-transform\n",
    "        y_pred_xgb_rain = np.maximum(0, y_pred_xgb_rain) # Asegurar no negatividad\n",
    "\n",
    "        print(\"\\nXGBoost – Predicción de Rainfall (evaluado en escala original):\")\n",
    "        print(f\"  R² (CV, escala log): {grid_search_xgb_rain.best_score_:.3f}\")\n",
    "        print(f\"  R² (Test, escala original): {r2_score(y_test_reg_rain, y_pred_xgb_rain):.3f}\")\n",
    "        print(f\"  RMSE (Test, escala original): {mean_squared_error(y_test_reg_rain, y_pred_xgb_rain, squared=False):.2f} mm\")\n",
    "    else:\n",
    "        print(\"Datos para XGBoost (Rainfall) no disponibles. Modelado omitido.\")\n",
    "else:\n",
    "    print(\"❌ XGBoost no está instalado en este entorno. Se omiten los modelos XGBoost.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0258664b-0d65-42bc-b51f-2a4ef16b9b01",
   "metadata": {},
   "source": [
    "### Celda 21: Modelos con XGBoost\n",
    "\n",
    "**Propósito:** Entrenar, optimizar y evaluar modelos `XGBRegressor` para las tareas de predicción de `MaxTemp` y `Rainfall`, si la librería XGBoost está instalada y disponible.\n",
    "\n",
    "**Detalles del Código:**\n",
    "1.  **Inicialización:** Variables para predicciones y modelos XGBoost (`y_pred_xgb_temp`, `best_xgb_temp_model`, etc.) se inicializan a `None`.\n",
    "2.  **Verificación de Disponibilidad:** El código se ejecuta solo si `xgb_available` es `True`.\n",
    "3.  **XGBoost para `MaxTemp`:**\n",
    "    *   Se verifica la disponibilidad de los datos de entrenamiento y el preprocesador.\n",
    "    *   Se crea una `Pipeline` con `preprocessor_reg_temp` y un `XGBRegressor`. Se incluyen parámetros comentados (`tree_method`, `enable_categorical`) que pueden ser útiles para versiones más recientes de XGBoost y para manejar características categóricas directamente si no se usa OneHotEncoding.\n",
    "    *   Se define `param_grid_xgb` para los hiperparámetros de XGBoost.\n",
    "    *   `GridSearchCV` con `cv_kfold` y `scoring='r2'` optimiza el modelo.\n",
    "    *   Se evalúa y se imprimen R² (CV y Test) y RMSE (Test).\n",
    "4.  **XGBoost para `Rainfall` (con Log-Transform):**\n",
    "    *   Se verifica la disponibilidad de los datos relevantes (incluyendo `y_train_reg_rain_log`).\n",
    "    *   Se crea una `Pipeline` similar, usando `preprocessor_reg_rain`.\n",
    "    *   `GridSearchCV` se ajusta usando `y_train_reg_rain_log`.\n",
    "    *   Las predicciones se invierten (`np.expm1`) y se ajustan para no ser negativas.\n",
    "    *   Se evalúa y se imprimen métricas (R² de CV en escala log, R² de Test y RMSE de Test en escala original).\n",
    "5.  **Mensaje Alternativo:** Si XGBoost no está instalado, se imprime un mensaje indicándolo.\n",
    "\n",
    "**Resultado Esperado:**\n",
    "Si XGBoost está instalado y los datos están listos:\n",
    "*   Mensajes de progreso y los mejores hiperparámetros para cada modelo XGBoost.\n",
    "*   Métricas R² y RMSE para la predicción de `MaxTemp` con XGBoost.\n",
    "*   Métricas R² y RMSE para la predicción de `Rainfall` con XGBoost (evaluadas en la escala original).\n",
    "Si XGBoost no está instalado o los datos no están listos, se mostrarán los mensajes correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d88841b-5119-426c-b09f-4e2e56d59015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualización: Comparación Predicción vs. Valor Real ---\n",
    "\n",
    "# Gráfico para MaxTemp\n",
    "if 'y_test_reg_temp' in globals() and y_test_reg_temp is not None:\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plot_title_temp = \"Predicción de MaxTemp vs. Real\"\n",
    "    predictions_exist_temp = False\n",
    "\n",
    "    # RandomForest Predicciones para MaxTemp\n",
    "    if 'y_pred_reg_temp' in globals() and y_pred_reg_temp is not None and not np.isnan(r2_temp):\n",
    "        sns.scatterplot(x=y_test_reg_temp, y=y_pred_reg_temp, alpha=0.6, edgecolor=None, s=50, label=\"Predicciones RF\")\n",
    "        plot_title_temp += f\"\\nRF R²: {r2_temp:.3f}, RMSE: {rmse_temp:.2f}°C\"\n",
    "        predictions_exist_temp = True\n",
    "    \n",
    "    # XGBoost Predicciones para MaxTemp (si existen)\n",
    "    if xgb_available and 'y_pred_xgb_temp' in globals() and y_pred_xgb_temp is not None:\n",
    "        try:\n",
    "            xgb_r2_temp_plot = r2_score(y_test_reg_temp, y_pred_xgb_temp)\n",
    "            xgb_rmse_temp_plot = mean_squared_error(y_test_reg_temp, y_pred_xgb_temp, squared=False)\n",
    "            if not np.isnan(xgb_r2_temp_plot):\n",
    "                 sns.scatterplot(x=y_test_reg_temp, y=y_pred_xgb_temp, alpha=0.6, color='darkorange', marker='x', s=50, label=\"Predicciones XGB\")\n",
    "                 plot_title_temp += f\"\\nXGB R²: {xgb_r2_temp_plot:.3f}, RMSE: {xgb_rmse_temp_plot:.2f}°C\"\n",
    "                 predictions_exist_temp = True\n",
    "        except Exception as e:\n",
    "            print(f\"Advertencia: No se pudieron calcular/plotear métricas XGB para MaxTemp: {e}\")\n",
    "\n",
    "\n",
    "    if predictions_exist_temp:\n",
    "        min_val_temp = y_test_reg_temp.min() \n",
    "        max_val_temp = y_test_reg_temp.max()\n",
    "        # Ajustar min/max si las predicciones están fuera del rango de y_test\n",
    "        if y_pred_reg_temp is not None:\n",
    "            min_val_temp = min(min_val_temp, pd.Series(y_pred_reg_temp).min())\n",
    "            max_val_temp = max(max_val_temp, pd.Series(y_pred_reg_temp).max())\n",
    "        if xgb_available and y_pred_xgb_temp is not None:\n",
    "            min_val_temp = min(min_val_temp, pd.Series(y_pred_xgb_temp).min())\n",
    "            max_val_temp = max(max_val_temp, pd.Series(y_pred_xgb_temp).max())\n",
    "\n",
    "        plt.plot([min_val_temp, max_val_temp], [min_val_temp, max_val_temp], 'r--', lw=2, label=\"Predicción Perfecta\")\n",
    "        \n",
    "        plt.xlabel(\"Temperatura Máxima Real (°C)\", fontsize=12)\n",
    "        plt.ylabel(\"Temperatura Máxima Predicha (°C)\", fontsize=12)\n",
    "        plt.title(plot_title_temp, fontsize=14)\n",
    "        plt.legend()\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.axis('equal') \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No hay predicciones válidas disponibles para graficar MaxTemp.\")\n",
    "else:\n",
    "    print(\"No se pueden generar gráficos de predicción vs real para MaxTemp (y_test_reg_temp no disponible).\")\n",
    "\n",
    "\n",
    "# Gráfico para Rainfall\n",
    "if 'y_test_reg_rain' in globals() and y_test_reg_rain is not None:\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plot_title_rain = \"Predicción de Rainfall vs. Real\"\n",
    "    predictions_exist_rain = False\n",
    "\n",
    "    # RandomForest Predicciones para Rainfall\n",
    "    if 'y_pred_reg_rain' in globals() and y_pred_reg_rain is not None and not np.isnan(r2_rain):\n",
    "        sns.scatterplot(x=y_test_reg_rain, y=y_pred_reg_rain, alpha=0.5, edgecolor=None, s=40, label=\"Predicciones RF\")\n",
    "        plot_title_rain += f\"\\nRF R²: {r2_rain:.3f}, RMSE: {rmse_rain:.2f} mm\"\n",
    "        predictions_exist_rain = True\n",
    "\n",
    "    # XGBoost Predicciones para Rainfall (si existen)\n",
    "    if xgb_available and 'y_pred_xgb_rain' in globals() and y_pred_xgb_rain is not None:\n",
    "        try:\n",
    "            xgb_r2_rain_plot = r2_score(y_test_reg_rain, y_pred_xgb_rain)\n",
    "            xgb_rmse_rain_plot = mean_squared_error(y_test_reg_rain, y_pred_xgb_rain, squared=False)\n",
    "            if not np.isnan(xgb_r2_rain_plot):\n",
    "                sns.scatterplot(x=y_test_reg_rain, y=y_pred_xgb_rain, alpha=0.5, color='darkorange', marker='x', s=40, label=\"Predicciones XGB\")\n",
    "                plot_title_rain += f\"\\nXGB R²: {xgb_r2_rain_plot:.3f}, RMSE: {xgb_rmse_rain_plot:.2f} mm\"\n",
    "                predictions_exist_rain = True\n",
    "        except Exception as e:\n",
    "            print(f\"Advertencia: No se pudieron calcular/plotear métricas XGB para Rainfall: {e}\")\n",
    "        \n",
    "    if predictions_exist_rain:\n",
    "        min_val_rain = 0 \n",
    "        # Calcular max_val_rain_data basado en y_test y las predicciones disponibles\n",
    "        max_val_rain_data = y_test_reg_rain.max()\n",
    "        if y_pred_reg_rain is not None:\n",
    "             max_val_rain_data = max(max_val_rain_data, pd.Series(y_pred_reg_rain).max())\n",
    "        if xgb_available and y_pred_xgb_rain is not None:\n",
    "            max_val_rain_data = max(max_val_rain_data, pd.Series(y_pred_xgb_rain).max())\n",
    "            \n",
    "        plot_max_rain = min(max_val_rain_data, np.percentile(y_test_reg_rain[y_test_reg_rain > 0], 99) * 1.5 if (y_test_reg_rain > 0).any() else max_val_rain_data)\n",
    "        plot_max_rain = max(plot_max_rain, 10) # Asegurar un rango mínimo visible si toda la lluvia es baja\n",
    "\n",
    "        plt.plot([min_val_rain, plot_max_rain], [min_val_rain, plot_max_rain], 'r--', lw=2, label=\"Predicción Perfecta\")\n",
    "        \n",
    "        plt.xlabel(\"Lluvia Real (mm)\", fontsize=12)\n",
    "        plt.ylabel(\"Lluvia Predicha (mm)\", fontsize=12)\n",
    "        plt.title(plot_title_rain, fontsize=14)\n",
    "        \n",
    "        plt.xlim(left=-1, right=plot_max_rain + 1) \n",
    "        plt.ylim(bottom=-1, top=plot_max_rain + 1)\n",
    "\n",
    "        plt.legend()\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        # plt.axis('equal') # Puede ser problemático para Rainfall si los rangos son muy diferentes. Mantener los límites explícitos.\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No hay predicciones válidas disponibles para graficar Rainfall.\")\n",
    "else:\n",
    "    print(\"No se pueden generar gráficos de predicción vs real para Rainfall (y_test_reg_rain no disponible).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb54c2f-490b-4aa4-80e5-e6f7e7587f59",
   "metadata": {},
   "source": [
    "### Celda 22: Comparación Gráfica: Predicción vs. Valor Real (Temperatura y Lluvia)\n",
    "\n",
    "**Propósito:** Visualizar qué tan bien se alinean las predicciones de los modelos de regresión (RandomForest y, opcionalmente, XGBoost) con los valores reales para `MaxTemp` y `Rainfall`.\n",
    "\n",
    "**Detalles del Código:**\n",
    "1.  **Gráfico para `MaxTemp`:**\n",
    "    *   Verifica si `y_test_reg_temp` existe.\n",
    "    *   Si las predicciones de RandomForest (`y_pred_reg_temp`) y sus métricas (`r2_temp`) son válidas, se plotean.\n",
    "    *   Si XGBoost está disponible y sus predicciones (`y_pred_xgb_temp`) son válidas, se calculan sus métricas y se superponen en el gráfico con un marcador y color diferente.\n",
    "    *   Se calcula un rango dinámico para la línea de \"Predicción Perfecta\" (y=x) basado en los valores reales y todas las predicciones disponibles.\n",
    "    *   El título del gráfico se actualiza dinámicamente para incluir las métricas de los modelos ploteados.\n",
    "    *   `plt.axis('equal')` asegura escalas iguales en los ejes para una correcta interpretación de la línea y=x.\n",
    "2.  **Gráfico para `Rainfall`:**\n",
    "    *   Proceso similar al de `MaxTemp`.\n",
    "    *   Para `plot_max_rain` (límite superior del gráfico de lluvia), se usa el percentil 99 de los valores reales de lluvia mayores que cero para evitar que outliers extremos distorsionen la visualización. Si no hay lluvia > 0, se usa el máximo. Se asegura un valor mínimo para `plot_max_rain` para una mejor visualización si toda la lluvia es muy baja.\n",
    "    *   Los límites de los ejes X e Y se establecen explícitamente. `plt.axis('equal')` se comenta para Rainfall, ya que a veces puede hacer que el gráfico sea menos legible si los rangos de predicción y real difieren mucho.\n",
    "3.  **Manejo de Errores:** Se incluyen mensajes si los datos necesarios para los gráficos no están disponibles.\n",
    "\n",
    "**Resultado Esperado:**\n",
    "*   Dos gráficos de dispersión:\n",
    "    *   Uno para `MaxTemp`, mostrando los valores reales vs. los predichos por RandomForest (y XGBoost si está disponible).\n",
    "    *   Uno para `Rainfall`, con una estructura similar.\n",
    "*   Ambos gráficos incluirán una línea diagonal roja de \"Predicción Perfecta\".\n",
    "*   Los títulos de los gráficos mostrarán las métricas R² y RMSE para los modelos correspondientes.\n",
    "*   Mensajes de advertencia o informativos si no se pueden generar los gráficos o calcular métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e61bde7-f4c2-43c5-8131-52bfec48e060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Resumen de Métricas Clave ---\n",
    "print(\"--- Resumen de Métricas Clave de los Modelos Optimizados ---\")\n",
    "\n",
    "# Clasificación\n",
    "lr_auc_final, rf_cls_auc_final = np.nan, np.nan \n",
    "\n",
    "if 'best_lr_model' in globals() and best_lr_model is not None and \\\n",
    "   'y_test_cls' in globals() and y_test_cls is not None and \\\n",
    "   'y_proba_lr' in globals() and y_proba_lr is not None:\n",
    "    try:\n",
    "        lr_auc_final = roc_auc_score(y_test_cls, y_proba_lr)\n",
    "        print(f\"\\nClasificación - Regresión Logística (RainTomorrow):\")\n",
    "        print(f\"  ROC AUC (Test): {lr_auc_final:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al obtener métricas finales LR Clasificación: {e}\")\n",
    "\n",
    "if 'best_rf_cls_model' in globals() and best_rf_cls_model is not None and \\\n",
    "   'y_test_cls' in globals() and y_test_cls is not None and \\\n",
    "   'y_proba_rf_cls' in globals() and y_proba_rf_cls is not None:\n",
    "    try:\n",
    "        rf_cls_auc_final = roc_auc_score(y_test_cls, y_proba_rf_cls)\n",
    "        print(f\"\\nClasificación - Random Forest (RainTomorrow):\")\n",
    "        print(f\"  ROC AUC (Test): {rf_cls_auc_final:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al obtener métricas finales RF Clasificación: {e}\")\n",
    "\n",
    "# Regresión MaxTemp (usando r2_temp, rmse_temp de la celda de modelado de MaxTemp RFR)\n",
    "if 'r2_temp' in globals() and not np.isnan(r2_temp) and \\\n",
    "   'rmse_temp' in globals() and not np.isnan(rmse_temp):\n",
    "    print(f\"\\nRegresión - Random Forest (MaxTemp):\")\n",
    "    print(f\"  R² (Test): {r2_temp:.3f}\")\n",
    "    print(f\"  RMSE (Test): {rmse_temp:.2f}°C\")\n",
    "else:\n",
    "    print(\"\\nMétricas para Random Forest (MaxTemp) no disponibles.\")\n",
    "\n",
    "\n",
    "# Regresión Rainfall (usando r2_rain, rmse_rain de la celda de modelado de Rainfall RFR)\n",
    "if 'r2_rain' in globals() and not np.isnan(r2_rain) and \\\n",
    "   'rmse_rain' in globals() and not np.isnan(rmse_rain):\n",
    "    print(f\"\\nRegresión - Random Forest (Rainfall):\")\n",
    "    print(f\"  R² (Test): {r2_rain:.3f}\")\n",
    "    print(f\"  RMSE (Test): {rmse_rain:.2f} mm\")\n",
    "else:\n",
    "    print(\"\\nMétricas para Random Forest (Rainfall) no disponibles.\")\n",
    "\n",
    "# XGBoost (si se ejecutó y las predicciones están disponibles)\n",
    "if xgb_available:\n",
    "    print(\"\\n--- Métricas XGBoost (si los modelos se entrenaron y evaluaron) ---\")\n",
    "    # XGBoost MaxTemp\n",
    "    if 'y_pred_xgb_temp' in globals() and y_pred_xgb_temp is not None and \\\n",
    "       'y_test_reg_temp' in globals() and y_test_reg_temp is not None:\n",
    "        try:\n",
    "            xgb_r2_temp_final = r2_score(y_test_reg_temp, y_pred_xgb_temp)\n",
    "            xgb_rmse_temp_final = mean_squared_error(y_test_reg_temp, y_pred_xgb_temp, squared=False)\n",
    "            if not np.isnan(xgb_r2_temp_final):\n",
    "                print(f\"\\nRegresión - XGBoost (MaxTemp):\")\n",
    "                print(f\"  R² (Test): {xgb_r2_temp_final:.3f}\")\n",
    "                print(f\"  RMSE (Test): {xgb_rmse_temp_final:.2f}°C\")\n",
    "            else:\n",
    "                print(\"\\nMétricas para XGBoost (MaxTemp) no calculadas (R² es NaN).\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al calcular métricas finales XGB Temp: {e}\")\n",
    "    else:\n",
    "        print(\"\\nPredicciones XGBoost (MaxTemp) o datos de prueba no disponibles para resumen.\")\n",
    "\n",
    "    # XGBoost Rainfall\n",
    "    if 'y_pred_xgb_rain' in globals() and y_pred_xgb_rain is not None and \\\n",
    "       'y_test_reg_rain' in globals() and y_test_reg_rain is not None:\n",
    "        try:\n",
    "            xgb_r2_rain_final = r2_score(y_test_reg_rain, y_pred_xgb_rain)\n",
    "            xgb_rmse_rain_final = mean_squared_error(y_test_reg_rain, y_pred_xgb_rain, squared=False)\n",
    "            if not np.isnan(xgb_r2_rain_final):\n",
    "                print(f\"\\nRegresión - XGBoost (Rainfall):\")\n",
    "                print(f\"  R² (Test): {xgb_r2_rain_final:.3f}\")\n",
    "                print(f\"  RMSE (Test): {xgb_rmse_rain_final:.2f} mm\")\n",
    "            else:\n",
    "                print(\"\\nMétricas para XGBoost (Rainfall) no calculadas (R² es NaN).\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al calcular métricas finales XGB Rain: {e}\")\n",
    "    else:\n",
    "        print(\"\\nPredicciones XGBoost (Rainfall) o datos de prueba no disponibles para resumen.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bad327-6401-47d8-aa0b-e513af210d15",
   "metadata": {},
   "source": [
    "### Celda 23: Resumen de Métricas, Conclusiones y Próximos Pasos\n",
    "\n",
    "**Propósito:** Esta sección finaliza el análisis resumiendo los hallazgos clave, discutiendo las limitaciones y sugiriendo posibles direcciones para trabajos futuros. La celda de código asociada imprime un resumen de las métricas de rendimiento de los modelos clave.\n",
    "\n",
    "**Detalles del Código (Celda de Python asociada):**\n",
    "*   El código Python imprime un resumen de las métricas de rendimiento finales (ROC AUC para clasificación; R² y RMSE para regresión) obtenidas en los conjuntos de prueba para los modelos optimizados.\n",
    "*   Se verifica la existencia de los modelos y las predicciones necesarias antes de intentar calcular o imprimir las métricas, para evitar errores si alguna parte del modelado fue omitida o falló.\n",
    "*   Las métricas de RandomForest para regresión (`r2_temp`, `rmse_temp`, `r2_rain`, `rmse_rain`) se toman de las variables globales calculadas en sus respectivas celdas de modelado.\n",
    "*   Las métricas de XGBoost se recalculan aquí si sus predicciones están disponibles, para asegurar que se usan los datos correctos del conjunto de prueba.\n",
    "*   Se incluyen bloques `try-except` y verificaciones de `np.isnan` para un resumen más robusto.\n",
    "\n",
    "---\n",
    "\n",
    "**Conclusiones Generales del Análisis Climático y Modelado:**\n",
    "\n",
    "1.  **Análisis Exploratorio de Datos (EDA) y Geopandas:**\n",
    "    *   El análisis se centró en tres ubicaciones alrededor de Melbourne: Melbourne, MelbourneAirport y Watsonia, mostrando patrones climáticos consistentes con su geografía.\n",
    "    *   Se identificaron patrones estacionales claros en la temperatura, lluvia y humedad, con visualizaciones como lineplots, boxplots y heatmaps que ayudaron a comprender estas tendencias.\n",
    "    *   La integración de `geopandas` y `folium` permitió la visualización espacial de las estaciones y datos agregados, mientras que `plotly.express` facilitó la exploración interactiva de relaciones multivariadas a lo largo del tiempo.\n",
    "\n",
    "2.  **Modelado de Clasificación (`RainTomorrow`):**\n",
    "    *   Se entrenaron modelos de Regresión Logística y Random Forest para predecir la probabilidad de lluvia al día siguiente.\n",
    "    *   El desbalance de clases en `RainTomorrow` fue abordado mediante `class_weight='balanced'` y validación cruzada estratificada, mejorando la sensibilidad de los modelos a la clase minoritaria (lluvia).\n",
    "    *   La optimización de hiperparámetros con `GridSearchCV` fue crucial para maximizar el rendimiento, medido principalmente por ROC AUC. Random Forest generalmente superó a la Regresión Logística.\n",
    "    *   Características como la humedad (especialmente `Humidity3pm`), la presión atmosférica y la ocurrencia de lluvia el día actual (`RainToday`) demostraron ser predictores importantes.\n",
    "\n",
    "3.  **Modelado de Regresión (`MaxTemp` y `Rainfall`):**\n",
    "    *   Se desarrollaron modelos `RandomForestRegressor` (y opcionalmente `XGBRegressor`) para predecir valores continuos de temperatura máxima y cantidad de lluvia.\n",
    "    *   **Predicción de `MaxTemp`:** Los modelos lograron un rendimiento notablemente bueno, con altos valores de R² y bajos RMSE, indicando que la temperatura máxima es relativamente predecible dadas las condiciones meteorológicas del día.\n",
    "    *   **Predicción de `Rainfall`:** La predicción de la cantidad de lluvia resultó más desafiante, lo cual es común dada su naturaleza más estocástica. La transformación logarítmica de la variable `Rainfall` fue un paso importante para normalizar su distribución y mejorar el rendimiento del modelo, aunque los valores de R² fueron modestos.\n",
    "\n",
    "**Limitaciones del Estudio:**\n",
    "\n",
    "*   **Alcance Geográfico:** El análisis se limitó a solo tres ubicaciones; una cobertura más amplia podría revelar patrones climáticos más diversos y complejos.\n",
    "*   **Imputación de Nulos:** Se utilizó imputación simple (media/moda). Estrategias más sofisticadas podrían preservar mejor la varianza y las relaciones en los datos.\n",
    "*   **Ingeniería de Características:** Aunque se crearon características basadas en la fecha, una ingeniería más profunda (ej., variables de lag, interacciones complejas, índices climáticos) podría desbloquear un mayor poder predictivo.\n",
    "*   **Validación Temporal:** El `train_test_split` estándar con mezcla (implícito en `GridSearchCV` con `KFold(shuffle=True)` para regresión) no respeta estrictamente la naturaleza secuencial de los datos climáticos. Esto podría llevar a una sobreestimación del rendimiento del modelo en un escenario de pronóstico real.\n",
    "*   **Complejidad del Modelo vs. Interpretabilidad:** Aunque modelos como Random Forest y XGBoost son potentes, su interpretabilidad directa puede ser menor que modelos más simples.\n",
    "\n",
    "**Próximos Pasos y Mejoras Potenciales:**\n",
    "\n",
    "1.  **Ingeniería de Características Avanzada:** Incorporar variables de lag (ej., lluvia o temperatura de días anteriores), términos de interacción significativos, y promedios móviles para capturar mejor las dinámicas temporales.\n",
    "2.  **Modelos Específicos para Series Temporales:** Explorar algoritmos como ARIMA, SARIMA, Prophet, o modelos de aprendizaje profundo como LSTMs, que están diseñados para datos secuenciales.\n",
    "3.  **Validación Cruzada Temporal Robusta:** Implementar `TimeSeriesSplit` de scikit-learn o estrategias de validación forward-chaining para una evaluación más realista del rendimiento predictivo.\n",
    "4.  **Análisis Geoespacial Extendido:** Con datos de más estaciones, realizar interpolaciones espaciales (ej., kriging) para crear mapas continuos, o analizar la autocorrelación espacial para entender la influencia de ubicaciones cercanas.\n",
    "5.  **Manejo Avanzado de Desbalance de Clases:** Para la clasificación, explorar técnicas de remuestreo como SMOTE (Synthetic Minority Over-sampling Technique) o ADASYN, además del ajuste de pesos.\n",
    "6.  **Optimización de Hiperparámetros Más Exhaustiva:** Utilizar técnicas de búsqueda más avanzadas como la optimización Bayesiana, o rangos de parámetros más amplios si los recursos computacionales lo permiten.\n",
    "7.  **Análisis de Incertidumbre:** Cuantificar la incertidumbre en las predicciones, especialmente para variables críticas como la cantidad de lluvia.\n",
    "\n",
    "Este proyecto mejorado establece una base sólida para el análisis climático y la aplicación de machine learning, destacando la importancia de un preprocesamiento cuidadoso, una evaluación rigurosa del modelo y la interpretabilidad de los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cb7995-102d-47da-b084-e20e510b7b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
